{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caravan insurance policy challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project uses the libraries below;\n",
    "- library(reshape2) for a plot\n",
    "- library(ggplot2) for a plot\n",
    "- library(gridExtra) for a grid plot\n",
    "- library(\"MASS\") for a plot of a probability density function\n",
    "- library(\"tidyverse\") for converting a dataframe\n",
    "- library(\"DiscriMiner\") for a calculation of correlation ratio\n",
    "- library(leaps) for modeling\n",
    "- library(\"caret\") for cross-validation\n",
    "- library(glmnet) for modeling and cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction of the prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project addresses distinguishing a caravan insurance policyholder or not. In addition, models used for prediction are also required to provide useful informationto understand why customers purchased the caravan insurance policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(warn=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data structure\n",
    "Firstly, have a look at the data given. Read and show data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 3 × 86</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>MOSTYPE</th><th scope=col>MAANTHUI</th><th scope=col>MGEMOMV</th><th scope=col>MGEMLEEF</th><th scope=col>MOSHOOFD</th><th scope=col>MGODRK</th><th scope=col>MGODPR</th><th scope=col>MGODOV</th><th scope=col>MGODGE</th><th scope=col>MRELGE</th><th scope=col>⋯</th><th scope=col>APERSONG</th><th scope=col>AGEZONG</th><th scope=col>AWAOREG</th><th scope=col>ABRAND</th><th scope=col>AZEILPL</th><th scope=col>APLEZIER</th><th scope=col>AFIETS</th><th scope=col>AINBOED</th><th scope=col>ABYSTAND</th><th scope=col>CARAVAN</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>⋯</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>37</td><td>1</td><td>2</td><td>2</td><td>8</td><td>1</td><td>4</td><td>1</td><td>4</td><td>6</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td>37</td><td>1</td><td>2</td><td>2</td><td>8</td><td>0</td><td>4</td><td>2</td><td>4</td><td>3</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "\t<tr><td> 9</td><td>1</td><td>3</td><td>3</td><td>3</td><td>2</td><td>3</td><td>2</td><td>4</td><td>5</td><td>⋯</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 3 × 86\n",
       "\\begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       " MOSTYPE & MAANTHUI & MGEMOMV & MGEMLEEF & MOSHOOFD & MGODRK & MGODPR & MGODOV & MGODGE & MRELGE & MRELSA & MRELOV & MFALLEEN & MFGEKIND & MFWEKIND & MOPLHOOG & MOPLMIDD & MOPLLAAG & MBERHOOG & MBERZELF & MBERBOER & MBERMIDD & MBERARBG & MBERARBO & MSKA & MSKB1 & MSKB2 & MSKC & MSKD & MHHUUR & MHKOOP & MAUT1 & MAUT2 & MAUT0 & MZFONDS & MZPART & MINKM30 & MINK3045 & MINK4575 & MINK7512 & MINK123M & MINKGEM & MKOOPKLA & PWAPART & PWABEDR & PWALAND & PPERSAUT & PBESAUT & PMOTSCO & PVRAAUT & PAANHANG & PTRACTOR & PWERKT & PBROM & PLEVEN & PPERSONG & PGEZONG & PWAOREG & PBRAND & PZEILPL & PPLEZIER & PFIETS & PINBOED & PBYSTAND & AWAPART & AWABEDR & AWALAND & APERSAUT & ABESAUT & AMOTSCO & AVRAAUT & AAANHANG & ATRACTOR & AWERKT & ABROM & ALEVEN & APERSONG & AGEZONG & AWAOREG & ABRAND & AZEILPL & APLEZIER & AFIETS & AINBOED & ABYSTAND & CARAVAN\\\\\n",
       " <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t 37 & 1 & 2 & 2 & 8 & 1 & 4 & 1 & 4 & 6 & 2 & 2 & 0 & 4 & 5 & 0 & 5 & 4 & 0 & 0 & 0 & 5 & 0 & 4 & 0 & 2 & 3 & 5 & 0 & 2 & 7 & 7 & 1 & 2 & 6 & 3 & 2 & 0 & 5 & 2 & 0 & 5 & 4 & 2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 2 & 0 & 0 & 0 & 0 & 0 & 2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t 37 & 1 & 2 & 2 & 8 & 0 & 4 & 2 & 4 & 3 & 2 & 4 & 4 & 4 & 2 & 0 & 5 & 4 & 0 & 0 & 0 & 7 & 0 & 2 & 0 & 5 & 0 & 4 & 0 & 7 & 2 & 7 & 0 & 2 & 9 & 0 & 4 & 5 & 0 & 0 & 0 & 3 & 4 & 2 & 0 & 0 & 6 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 2 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\t  9 & 1 & 3 & 3 & 3 & 2 & 3 & 2 & 4 & 5 & 2 & 2 & 2 & 3 & 4 & 3 & 4 & 2 & 4 & 0 & 0 & 3 & 1 & 2 & 3 & 2 & 1 & 4 & 0 & 5 & 4 & 9 & 0 & 0 & 7 & 2 & 1 & 5 & 3 & 0 & 0 & 4 & 4 & 0 & 0 & 0 & 6 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 2 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 3 × 86\n",
       "\n",
       "| MOSTYPE &lt;int&gt; | MAANTHUI &lt;int&gt; | MGEMOMV &lt;int&gt; | MGEMLEEF &lt;int&gt; | MOSHOOFD &lt;int&gt; | MGODRK &lt;int&gt; | MGODPR &lt;int&gt; | MGODOV &lt;int&gt; | MGODGE &lt;int&gt; | MRELGE &lt;int&gt; | ⋯ ⋯ | APERSONG &lt;int&gt; | AGEZONG &lt;int&gt; | AWAOREG &lt;int&gt; | ABRAND &lt;int&gt; | AZEILPL &lt;int&gt; | APLEZIER &lt;int&gt; | AFIETS &lt;int&gt; | AINBOED &lt;int&gt; | ABYSTAND &lt;int&gt; | CARAVAN &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 37 | 1 | 2 | 2 | 8 | 1 | 4 | 1 | 4 | 6 | ⋯ | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "| 37 | 1 | 2 | 2 | 8 | 0 | 4 | 2 | 4 | 3 | ⋯ | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "|  9 | 1 | 3 | 3 | 3 | 2 | 3 | 2 | 4 | 5 | ⋯ | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  MOSTYPE MAANTHUI MGEMOMV MGEMLEEF MOSHOOFD MGODRK MGODPR MGODOV MGODGE MRELGE\n",
       "1 37      1        2       2        8        1      4      1      4      6     \n",
       "2 37      1        2       2        8        0      4      2      4      3     \n",
       "3  9      1        3       3        3        2      3      2      4      5     \n",
       "  <U+22EF>        APERSONG AGEZONG AWAOREG ABRAND AZEILPL APLEZIER AFIETS AINBOED\n",
       "1 <U+22EF> 0        0       0       1      0       0        0      0      \n",
       "2 <U+22EF> 0        0       0       1      0       0        0      0      \n",
       "3 <U+22EF> 0        0       0       1      0       0        0      0      \n",
       "  ABYSTAND CARAVAN\n",
       "1 0        0      \n",
       "2 0        0      \n",
       "3 0        0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = read.delim(sep = \"\\t\", file = \"./data//ticdata2000.txt\")\n",
    "cols.initial=c('MOSTYPE','MAANTHUI','MGEMOMV','MGEMLEEF','MOSHOOFD','MGODRK','MGODPR','MGODOV','MGODGE','MRELGE','MRELSA','MRELOV','MFALLEEN','MFGEKIND','MFWEKIND','MOPLHOOG','MOPLMIDD','MOPLLAAG','MBERHOOG','MBERZELF','MBERBOER','MBERMIDD','MBERARBG','MBERARBO','MSKA','MSKB1','MSKB2','MSKC','MSKD','MHHUUR','MHKOOP','MAUT1','MAUT2','MAUT0','MZFONDS','MZPART','MINKM30','MINK3045','MINK4575','MINK7512','MINK123M','MINKGEM','MKOOPKLA','PWAPART','PWABEDR','PWALAND','PPERSAUT','PBESAUT','PMOTSCO','PVRAAUT','PAANHANG','PTRACTOR','PWERKT','PBROM','PLEVEN','PPERSONG','PGEZONG','PWAOREG','PBRAND','PZEILPL','PPLEZIER','PFIETS','PINBOED','PBYSTAND','AWAPART','AWABEDR','AWALAND','APERSAUT','ABESAUT','AMOTSCO','AVRAAUT','AAANHANG','ATRACTOR','AWERKT','ABROM','ALEVEN','APERSONG','AGEZONG','AWAOREG','ABRAND','AZEILPL','APLEZIER','AFIETS','AINBOED','ABYSTAND','CARAVAN')\n",
    "names(df)=cols.initial\n",
    "head(df, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, confirm the number of observations and variables, and data types. Possible models depend on the number of observations and features. Hence, it is important to check that information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t5821 obs. of  86 variables:\n",
      " $ MOSTYPE : int  37 37 9 40 23 39 33 33 11 10 ...\n",
      " $ MAANTHUI: int  1 1 1 1 1 2 1 1 2 1 ...\n",
      " $ MGEMOMV : int  2 2 3 4 2 3 2 2 3 4 ...\n",
      " $ MGEMLEEF: int  2 2 3 2 1 2 3 4 3 3 ...\n",
      " $ MOSHOOFD: int  8 8 3 10 5 9 8 8 3 3 ...\n",
      " $ MGODRK  : int  1 0 2 1 0 2 0 0 3 1 ...\n",
      " $ MGODPR  : int  4 4 3 4 5 2 7 1 5 4 ...\n",
      " $ MGODOV  : int  1 2 2 1 0 0 0 3 0 1 ...\n",
      " $ MGODGE  : int  4 4 4 4 5 5 2 6 2 4 ...\n",
      " $ MRELGE  : int  6 3 5 7 0 7 7 6 7 7 ...\n",
      " $ MRELSA  : int  2 2 2 1 6 2 2 0 0 1 ...\n",
      " $ MRELOV  : int  2 4 2 2 3 0 0 3 2 2 ...\n",
      " $ MFALLEEN: int  0 4 2 2 3 0 0 3 2 0 ...\n",
      " $ MFGEKIND: int  4 4 3 4 5 3 5 3 2 3 ...\n",
      " $ MFWEKIND: int  5 2 4 4 2 6 4 3 6 6 ...\n",
      " $ MOPLHOOG: int  0 0 3 5 0 0 0 0 0 4 ...\n",
      " $ MOPLMIDD: int  5 5 4 4 5 4 3 1 4 3 ...\n",
      " $ MOPLLAAG: int  4 4 2 0 4 5 6 8 5 3 ...\n",
      " $ MBERHOOG: int  0 0 4 0 2 0 2 1 2 0 ...\n",
      " $ MBERZELF: int  0 0 0 5 0 0 0 1 0 0 ...\n",
      " $ MBERBOER: int  0 0 0 4 0 0 0 0 0 0 ...\n",
      " $ MBERMIDD: int  5 7 3 0 4 4 2 1 3 9 ...\n",
      " $ MBERARBG: int  0 0 1 0 2 1 5 8 3 0 ...\n",
      " $ MBERARBO: int  4 2 2 0 2 5 2 1 3 0 ...\n",
      " $ MSKA    : int  0 0 3 9 2 0 2 1 1 3 ...\n",
      " $ MSKB1   : int  2 5 2 0 2 1 1 1 2 0 ...\n",
      " $ MSKB2   : int  3 0 1 0 2 4 2 0 1 6 ...\n",
      " $ MSKC    : int  5 4 4 0 4 5 5 8 4 0 ...\n",
      " $ MSKD    : int  0 0 0 0 2 0 2 1 2 0 ...\n",
      " $ MHHUUR  : int  2 7 5 4 9 6 0 9 0 0 ...\n",
      " $ MHKOOP  : int  7 2 4 5 0 3 9 0 9 9 ...\n",
      " $ MAUT1   : int  7 7 9 6 5 8 4 5 6 6 ...\n",
      " $ MAUT2   : int  1 0 0 2 3 0 4 2 1 2 ...\n",
      " $ MAUT0   : int  2 2 0 1 3 1 2 3 2 1 ...\n",
      " $ MZFONDS : int  6 9 7 5 9 9 6 7 6 5 ...\n",
      " $ MZPART  : int  3 0 2 4 0 0 3 2 3 4 ...\n",
      " $ MINKM30 : int  2 4 1 0 5 4 2 7 2 0 ...\n",
      " $ MINK3045: int  0 5 5 0 2 3 5 2 3 3 ...\n",
      " $ MINK4575: int  5 0 3 9 3 3 3 1 3 2 ...\n",
      " $ MINK7512: int  2 0 0 0 0 0 0 0 1 2 ...\n",
      " $ MINK123M: int  0 0 0 0 0 0 0 0 0 2 ...\n",
      " $ MINKGEM : int  5 3 4 6 3 3 3 2 4 8 ...\n",
      " $ MKOOPKLA: int  4 4 4 3 3 5 3 3 7 7 ...\n",
      " $ PWAPART : int  2 2 0 0 0 0 0 0 2 0 ...\n",
      " $ PWABEDR : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PWALAND : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PPERSAUT: int  0 6 6 0 6 6 0 5 0 6 ...\n",
      " $ PBESAUT : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PMOTSCO : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PVRAAUT : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PAANHANG: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PTRACTOR: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PWERKT  : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PBROM   : int  0 0 0 0 0 0 3 0 0 0 ...\n",
      " $ PLEVEN  : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PPERSONG: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PGEZONG : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PWAOREG : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PBRAND  : int  2 2 2 6 0 0 0 0 3 0 ...\n",
      " $ PZEILPL : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PPLEZIER: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PFIETS  : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PINBOED : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PBYSTAND: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ AWAPART : int  2 1 0 0 0 0 0 0 1 0 ...\n",
      " $ AWABEDR : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ AWALAND : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ APERSAUT: int  0 1 1 0 1 1 0 1 0 1 ...\n",
      " $ ABESAUT : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ AMOTSCO : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ AVRAAUT : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ AAANHANG: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ ATRACTOR: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ AWERKT  : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ ABROM   : int  0 0 0 0 0 0 1 0 0 0 ...\n",
      " $ ALEVEN  : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ APERSONG: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ AGEZONG : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ AWAOREG : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ ABRAND  : int  1 1 1 1 0 0 0 0 1 0 ...\n",
      " $ AZEILPL : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ APLEZIER: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ AFIETS  : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ AINBOED : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ ABYSTAND: int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ CARAVAN : int  0 0 0 0 0 0 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "str(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **5821 observations** and **86 variables** including CARAVAN, which is the response variable. All of the features are integer data type.\n",
    "\n",
    "Next, have a look at the number of the caravan policyholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "348"
      ],
      "text/latex": [
       "348"
      ],
      "text/markdown": [
       "348"
      ],
      "text/plain": [
       "[1] 348"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(df[,\"CARAVAN\"]==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**348** out of 5821 observations are the caravan policyholders. \n",
    "\n",
    "It is figured out that the ratio of the policyholders is low, **approximately 6%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representative values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To grasp the nature of variables, looking through the representative values among independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    MOSTYPE         MAANTHUI         MGEMOMV         MGEMLEEF    \n",
       " Min.   : 1.00   Min.   : 1.000   Min.   :1.000   Min.   :1.000  \n",
       " 1st Qu.:10.00   1st Qu.: 1.000   1st Qu.:2.000   1st Qu.:2.000  \n",
       " Median :30.00   Median : 1.000   Median :3.000   Median :3.000  \n",
       " Mean   :24.25   Mean   : 1.111   Mean   :2.679   Mean   :2.991  \n",
       " 3rd Qu.:35.00   3rd Qu.: 1.000   3rd Qu.:3.000   3rd Qu.:3.000  \n",
       " Max.   :41.00   Max.   :10.000   Max.   :5.000   Max.   :6.000  \n",
       "    MOSHOOFD          MGODRK           MGODPR          MGODOV    \n",
       " Min.   : 1.000   Min.   :0.0000   Min.   :0.000   Min.   :0.00  \n",
       " 1st Qu.: 3.000   1st Qu.:0.0000   1st Qu.:4.000   1st Qu.:0.00  \n",
       " Median : 7.000   Median :0.0000   Median :5.000   Median :1.00  \n",
       " Mean   : 5.773   Mean   :0.6966   Mean   :4.627   Mean   :1.07  \n",
       " 3rd Qu.: 8.000   3rd Qu.:1.0000   3rd Qu.:6.000   3rd Qu.:2.00  \n",
       " Max.   :10.000   Max.   :9.0000   Max.   :9.000   Max.   :5.00  \n",
       "     MGODGE          MRELGE          MRELSA           MRELOV     \n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.0000   Min.   :0.000  \n",
       " 1st Qu.:2.000   1st Qu.:5.000   1st Qu.:0.0000   1st Qu.:1.000  \n",
       " Median :3.000   Median :6.000   Median :1.0000   Median :2.000  \n",
       " Mean   :3.259   Mean   :6.183   Mean   :0.8837   Mean   :2.291  \n",
       " 3rd Qu.:4.000   3rd Qu.:7.000   3rd Qu.:1.0000   3rd Qu.:3.000  \n",
       " Max.   :9.000   Max.   :9.000   Max.   :7.0000   Max.   :9.000  \n",
       "    MFALLEEN        MFGEKIND        MFWEKIND      MOPLHOOG        MOPLMIDD    \n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.0   Min.   :0.000   Min.   :0.000  \n",
       " 1st Qu.:0.000   1st Qu.:2.000   1st Qu.:3.0   1st Qu.:0.000   1st Qu.:2.000  \n",
       " Median :2.000   Median :3.000   Median :4.0   Median :1.000   Median :3.000  \n",
       " Mean   :1.888   Mean   :3.231   Mean   :4.3   Mean   :1.461   Mean   :3.351  \n",
       " 3rd Qu.:3.000   3rd Qu.:4.000   3rd Qu.:6.0   3rd Qu.:2.000   3rd Qu.:4.000  \n",
       " Max.   :9.000   Max.   :9.000   Max.   :9.0   Max.   :9.000   Max.   :9.000  \n",
       "    MOPLLAAG        MBERHOOG        MBERZELF        MBERBOER     \n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.0000  \n",
       " 1st Qu.:3.000   1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.0000  \n",
       " Median :5.000   Median :2.000   Median :0.000   Median :0.0000  \n",
       " Mean   :4.572   Mean   :1.895   Mean   :0.398   Mean   :0.5222  \n",
       " 3rd Qu.:6.000   3rd Qu.:3.000   3rd Qu.:1.000   3rd Qu.:1.0000  \n",
       " Max.   :9.000   Max.   :9.000   Max.   :5.000   Max.   :9.0000  \n",
       "    MBERMIDD        MBERARBG        MBERARBO          MSKA      \n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.000  \n",
       " 1st Qu.:2.000   1st Qu.:1.000   1st Qu.:1.000   1st Qu.:0.000  \n",
       " Median :3.000   Median :2.000   Median :2.000   Median :1.000  \n",
       " Mean   :2.899   Mean   :2.219   Mean   :2.306   Mean   :1.621  \n",
       " 3rd Qu.:4.000   3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:2.000  \n",
       " Max.   :9.000   Max.   :9.000   Max.   :9.000   Max.   :9.000  \n",
       "     MSKB1           MSKB2            MSKC            MSKD      \n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.000  \n",
       " 1st Qu.:1.000   1st Qu.:1.000   1st Qu.:2.000   1st Qu.:0.000  \n",
       " Median :2.000   Median :2.000   Median :4.000   Median :1.000  \n",
       " Mean   :1.607   Mean   :2.203   Mean   :3.758   Mean   :1.067  \n",
       " 3rd Qu.:2.000   3rd Qu.:3.000   3rd Qu.:5.000   3rd Qu.:2.000  \n",
       " Max.   :9.000   Max.   :9.000   Max.   :9.000   Max.   :9.000  \n",
       "     MHHUUR          MHKOOP          MAUT1          MAUT2           MAUT0     \n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.00   Min.   :0.000   Min.   :0.00  \n",
       " 1st Qu.:2.000   1st Qu.:2.000   1st Qu.:5.00   1st Qu.:0.000   1st Qu.:1.00  \n",
       " Median :4.000   Median :5.000   Median :6.00   Median :1.000   Median :2.00  \n",
       " Mean   :4.237   Mean   :4.771   Mean   :6.04   Mean   :1.317   Mean   :1.96  \n",
       " 3rd Qu.:7.000   3rd Qu.:7.000   3rd Qu.:7.00   3rd Qu.:2.000   3rd Qu.:3.00  \n",
       " Max.   :9.000   Max.   :9.000   Max.   :9.00   Max.   :7.000   Max.   :9.00  \n",
       "    MZFONDS          MZPART         MINKM30         MINK3045    \n",
       " Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.000  \n",
       " 1st Qu.:5.000   1st Qu.:1.000   1st Qu.:1.000   1st Qu.:2.000  \n",
       " Median :7.000   Median :2.000   Median :2.000   Median :4.000  \n",
       " Mean   :6.277   Mean   :2.729   Mean   :2.574   Mean   :3.536  \n",
       " 3rd Qu.:8.000   3rd Qu.:4.000   3rd Qu.:4.000   3rd Qu.:5.000  \n",
       " Max.   :9.000   Max.   :9.000   Max.   :9.000   Max.   :9.000  \n",
       "    MINK4575        MINK7512         MINK123M         MINKGEM     \n",
       " Min.   :0.000   Min.   :0.0000   Min.   :0.0000   Min.   :0.000  \n",
       " 1st Qu.:1.000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:3.000  \n",
       " Median :3.000   Median :0.0000   Median :0.0000   Median :4.000  \n",
       " Mean   :2.731   Mean   :0.7963   Mean   :0.2027   Mean   :3.784  \n",
       " 3rd Qu.:4.000   3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:4.000  \n",
       " Max.   :9.000   Max.   :9.0000   Max.   :9.0000   Max.   :9.000  \n",
       "    MKOOPKLA        PWAPART          PWABEDR           PWALAND       \n",
       " Min.   :1.000   Min.   :0.0000   Min.   :0.00000   Min.   :0.00000  \n",
       " 1st Qu.:3.000   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.00000  \n",
       " Median :4.000   Median :0.0000   Median :0.00000   Median :0.00000  \n",
       " Mean   :4.237   Mean   :0.7713   Mean   :0.04003   Mean   :0.07164  \n",
       " 3rd Qu.:6.000   3rd Qu.:2.0000   3rd Qu.:0.00000   3rd Qu.:0.00000  \n",
       " Max.   :8.000   Max.   :3.0000   Max.   :6.00000   Max.   :4.00000  \n",
       "    PPERSAUT       PBESAUT           PMOTSCO          PVRAAUT        \n",
       " Min.   :0.00   Min.   :0.00000   Min.   :0.0000   Min.   :0.000000  \n",
       " 1st Qu.:0.00   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.000000  \n",
       " Median :5.00   Median :0.00000   Median :0.0000   Median :0.000000  \n",
       " Mean   :2.97   Mean   :0.04827   Mean   :0.1754   Mean   :0.009449  \n",
       " 3rd Qu.:6.00   3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.000000  \n",
       " Max.   :8.00   Max.   :7.00000   Max.   :7.0000   Max.   :9.000000  \n",
       "    PAANHANG          PTRACTOR          PWERKT            PBROM       \n",
       " Min.   :0.00000   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000  \n",
       " 1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000  \n",
       " Median :0.00000   Median :0.0000   Median :0.00000   Median :0.0000  \n",
       " Mean   :0.02096   Mean   :0.0926   Mean   :0.01306   Mean   :0.2151  \n",
       " 3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.00000   3rd Qu.:0.0000  \n",
       " Max.   :5.00000   Max.   :6.0000   Max.   :6.00000   Max.   :6.0000  \n",
       "     PLEVEN          PPERSONG          PGEZONG           PWAOREG       \n",
       " Min.   :0.0000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000  \n",
       " 1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.00000  \n",
       " Median :0.0000   Median :0.00000   Median :0.00000   Median :0.00000  \n",
       " Mean   :0.1948   Mean   :0.01374   Mean   :0.01529   Mean   :0.02354  \n",
       " 3rd Qu.:0.0000   3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.00000  \n",
       " Max.   :9.0000   Max.   :6.00000   Max.   :3.00000   Max.   :7.00000  \n",
       "     PBRAND         PZEILPL            PPLEZIER          PFIETS       \n",
       " Min.   :0.000   Min.   :0.000000   Min.   :0.0000   Min.   :0.00000  \n",
       " 1st Qu.:0.000   1st Qu.:0.000000   1st Qu.:0.0000   1st Qu.:0.00000  \n",
       " Median :2.000   Median :0.000000   Median :0.0000   Median :0.00000  \n",
       " Mean   :1.827   Mean   :0.000859   Mean   :0.0189   Mean   :0.02525  \n",
       " 3rd Qu.:4.000   3rd Qu.:0.000000   3rd Qu.:0.0000   3rd Qu.:0.00000  \n",
       " Max.   :8.000   Max.   :3.000000   Max.   :6.0000   Max.   :1.00000  \n",
       "    PINBOED           PBYSTAND          AWAPART         AWABEDR       \n",
       " Min.   :0.00000   Min.   :0.00000   Min.   :0.000   Min.   :0.00000  \n",
       " 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.000   1st Qu.:0.00000  \n",
       " Median :0.00000   Median :0.00000   Median :0.000   Median :0.00000  \n",
       " Mean   :0.01563   Mean   :0.04759   Mean   :0.403   Mean   :0.01477  \n",
       " 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:1.000   3rd Qu.:0.00000  \n",
       " Max.   :6.00000   Max.   :5.00000   Max.   :2.000   Max.   :5.00000  \n",
       "    AWALAND           APERSAUT         ABESAUT           AMOTSCO       \n",
       " Min.   :0.00000   Min.   :0.0000   Min.   :0.00000   Min.   :0.00000  \n",
       " 1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.00000  \n",
       " Median :0.00000   Median :1.0000   Median :0.00000   Median :0.00000  \n",
       " Mean   :0.02062   Mean   :0.5621   Mean   :0.01048   Mean   :0.04106  \n",
       " 3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:0.00000  \n",
       " Max.   :1.00000   Max.   :7.0000   Max.   :4.00000   Max.   :8.00000  \n",
       "    AVRAAUT            AAANHANG          ATRACTOR           AWERKT        \n",
       " Min.   :0.000000   Min.   :0.00000   Min.   :0.00000   Min.   :0.000000  \n",
       " 1st Qu.:0.000000   1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.000000  \n",
       " Median :0.000000   Median :0.00000   Median :0.00000   Median :0.000000  \n",
       " Mean   :0.002233   Mean   :0.01254   Mean   :0.03367   Mean   :0.006185  \n",
       " 3rd Qu.:0.000000   3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.000000  \n",
       " Max.   :3.000000   Max.   :3.00000   Max.   :4.00000   Max.   :6.000000  \n",
       "     ABROM             ALEVEN           APERSONG           AGEZONG        \n",
       " Min.   :0.00000   Min.   :0.00000   Min.   :0.000000   Min.   :0.000000  \n",
       " 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.000000   1st Qu.:0.000000  \n",
       " Median :0.00000   Median :0.00000   Median :0.000000   Median :0.000000  \n",
       " Mean   :0.07043   Mean   :0.07662   Mean   :0.005326   Mean   :0.006528  \n",
       " 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.000000   3rd Qu.:0.000000  \n",
       " Max.   :2.00000   Max.   :8.00000   Max.   :1.000000   Max.   :1.000000  \n",
       "    AWAOREG             ABRAND        AZEILPL             APLEZIER       \n",
       " Min.   :0.000000   Min.   :0.00   Min.   :0.0000000   Min.   :0.000000  \n",
       " 1st Qu.:0.000000   1st Qu.:0.00   1st Qu.:0.0000000   1st Qu.:0.000000  \n",
       " Median :0.000000   Median :1.00   Median :0.0000000   Median :0.000000  \n",
       " Mean   :0.004638   Mean   :0.57   Mean   :0.0005154   Mean   :0.006013  \n",
       " 3rd Qu.:0.000000   3rd Qu.:1.00   3rd Qu.:0.0000000   3rd Qu.:0.000000  \n",
       " Max.   :2.000000   Max.   :7.00   Max.   :1.0000000   Max.   :2.000000  \n",
       "     AFIETS           AINBOED            ABYSTAND          CARAVAN       \n",
       " Min.   :0.00000   Min.   :0.000000   Min.   :0.00000   Min.   :0.00000  \n",
       " 1st Qu.:0.00000   1st Qu.:0.000000   1st Qu.:0.00000   1st Qu.:0.00000  \n",
       " Median :0.00000   Median :0.000000   Median :0.00000   Median :0.00000  \n",
       " Mean   :0.03178   Mean   :0.007902   Mean   :0.01426   Mean   :0.05978  \n",
       " 3rd Qu.:0.00000   3rd Qu.:0.000000   3rd Qu.:0.00000   3rd Qu.:0.00000  \n",
       " Max.   :3.00000   Max.   :2.000000   Max.   :2.00000   Max.   :1.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the variables beginning with the capital \"P\" and \"A\" show **zero medians**.\n",
    "\n",
    "Those variables are relating to **the number of contributions** and **the number of policies** according to the [data dictionary](http://kdd.ics.uci.edu/databases/tic/tic.html).\n",
    "\n",
    "It would indicate that they are **sparse variables** and their frequency are low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing the variable with the data dictionary given"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deepen the understanding of features, categorise independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Categorical variables\n",
    "\n",
    "    According to the data dictionary, **only MOSTYPE and MOSHOOFD** are categorical variables.\n",
    "    \n",
    "    \n",
    "2. Ordinal variables\n",
    "\n",
    "    The features beginning **the capital M and P** are ordinal variables denoting the percentage and the amount of contribution respectively.\n",
    "\n",
    "\n",
    "3. Continuous variables\n",
    "\n",
    "    The features of **MAANTHUI, MGEMOMV, MGEMLEEF and ones beginning the capital A** are continuous variables.\n",
    "\n",
    "\n",
    "4. Corresponding variables\n",
    "\n",
    "    The features beginning **the capital P and A are corresponding together**. \n",
    "    \n",
    "    For example, PWAPART and AWAPART represent the contribution and the number of private third party insurance respectively. \n",
    "    \n",
    "    **It is assumed that those corresponding variables are highly correlated**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncover the nature of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOSTYPE and MOSHOOFD are categorical variables.\n",
    "\n",
    "To grasp the distribution of those variables, plot tables and histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the table and histogram\n",
    "\n",
    "The blue histogram represents the frequency of the caravan policyholders, whereas the non-caravan policyholders are denoted as the red one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  1   2   3   4   5   6   7   8   9  10  11  12  13  15  16  17  18  19  20  21 \n",
       "124  82 249  52  45 119  44 339 278 165 153 111 179   5  16   9  19   3  25  15 \n",
       " 22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41 \n",
       " 98 251 180  82  48  50  25  86 118 205 141 809 182 214 225 132 339 328  71 205 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHgCAMAAAC7G6qeAAAAPFBMVEUAAAAAAP9NTU1oaGh8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",
      "text/plain": [
       "Plot with title \"Histogram of MOSTYPE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.height=4,repr.plot.width=6)\n",
    "hist(df[df[,\"CARAVAN\"]==0, \"MOSTYPE\"], breaks=seq(1,41), xlab=\"value\", main=\"Histogram of MOSTYPE\", col = \"#ff00ff40\", border = \"#ff00ff\")\n",
    "hist(df[df[,\"CARAVAN\"]==1, \"MOSTYPE\"], breaks=seq(1,41), col = \"#0000ff40\", border = \"#0000ff\", add=TRUE)\n",
    "table(df[,\"MOSTYPE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no bin in which the ratio of a caravan policyholder is high.\n",
    "\n",
    "One finding is that there is **no value of 14 in MOSTYPE**. It means that when generating dummy variables, the dummied feature of this value should not be produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   1    2    3    4    5    6    7    8    9   10 \n",
       " 552  502  886   52  569  205  550 1562  667  276 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAFoCAMAAAC46dgSAAAAPFBMVEUAAAAAAP9NTU1oaGh8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\nSUVORK5CYII=",
      "text/plain": [
       "Plot with title \"Histogram of MOSHOOFD\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.height=3,repr.plot.width=4)\n",
    "hist(df[df[,\"CARAVAN\"]==0, \"MOSHOOFD\"], breaks=seq(1,10), xlab=\"value\", main=\"Histogram of MOSHOOFD\", col = \"#ff00ff40\", border = \"#ff00ff\")\n",
    "hist(df[df[,\"CARAVAN\"]==1, \"MOSHOOFD\"], breaks=seq(1,10), col = \"#0000ff40\", border = \"#0000ff\", add=TRUE)\n",
    "table(df[,\"MOSHOOFD\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, there is no bin in which the ratio of a caravan policyholder is high.\n",
    "\n",
    "Differently, all categorical values in MOSHOOFD exit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Correlation between the corresponding ordinal variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned, the features beginning the capital P and A are corresponding.\n",
    "\n",
    "Since correlations between independent variables affect some models, it is important to check it.\n",
    "\n",
    "To check the correlations of those variables, plot a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables starting with the capital P and A\n",
    "cols.cor.capp=c('PWAPART','PWABEDR','PWALAND','PPERSAUT','PBESAUT','PMOTSCO','PVRAAUT','PAANHANG','PTRACTOR','PWERKT','PBROM','PLEVEN','PPERSONG','PGEZONG','PWAOREG','PBRAND','PZEILPL','PPLEZIER','PFIETS','PINBOED','PBYSTAND')\n",
    "cols.cor.capa=c('AWAPART','AWABEDR','AWALAND','APERSAUT','ABESAUT','AMOTSCO','AVRAAUT','AAANHANG','ATRACTOR','AWERKT','ABROM','ALEVEN','APERSONG','AGEZONG','AWAOREG','ABRAND','AZEILPL','APLEZIER','AFIETS','AINBOED','ABYSTAND')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHgCAMAAAC7G6qeAAACjlBMVEUAAAATK0MTK0QULUUU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\ngg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the heatmap of\n",
    "library(reshape2)\n",
    "library(ggplot2)\n",
    "options(repr.plot.height=4,repr.plot.width=6)\n",
    "ggplot(data = melt(cor(x=df[,cols.cor.capp],y=df[,cols.cor.capa] )), aes(x=Var1, y=Var2, fill=value)) + \n",
    "    geom_tile()+\n",
    "    scale_color_hue(name = \"correlation\")+\n",
    "    labs(x = \"Capital P\", y = \"Capital A\")+\n",
    "    theme(axis.text.x = element_text(angle = 90, hjust = 1, size=6),\n",
    "          axis.text.y = element_text(size=6),plot.caption = element_text(size = 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this plot shows, the corresponding variable pairs are highly correlated together.\n",
    "\n",
    "Since a pair of the corresponding variables describe each other, one of them would be unnecessary to hold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous section, check the correlations between independent variables.\n",
    "\n",
    "Note: variables beginning with the capital P are excluded from the targets of this section since they are represented by the capital A variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(\"tidyverse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate the list of correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all independent variables except the categorical and the capital P variables.\n",
    "cols=setdiff(colnames(df), c(\"MOSTYPE\",\"MOSHOOFD\", cols.cor.capp))\n",
    "data.frame(cor(df[cols])) %>% rownames_to_column(var = \"idx\") %>% gather(key, value, -idx) ->df.cor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Filter into highly correlated pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking up pairs having more than 0.8 correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all combinations correlating over abs(0.8)\n",
    "df.cor.high=df.cor[(abs(df.cor[\"value\"])>=.8)&(abs(df.cor[\"value\"])<1),]\n",
    "# Remove duplicated combinations\n",
    "hihg_cor_vec=list()\n",
    "for(i in seq(1,nrow(df.cor.high),1)){\n",
    "    elm=list(sort(c(df.cor.high[i,\"idx\"], df.cor.high[i,\"key\"])))\n",
    "    hihg_cor_vec=append(hihg_cor_vec, elm)\n",
    "}\n",
    "cols.cor.high.pairs=unique(hihg_cor_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Draw scatter plots about the highly correlated pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.cor.high=list()\n",
    "for (i in seq(1,length(cols.cor.high.pairs))){\n",
    "    labelX=cols.cor.high.pairs[[i]][1]\n",
    "    labelY=cols.cor.high.pairs[[i]][2]\n",
    "    plots.cor.high[[i]]=ggplot(data=df, aes_(x=as.name(labelX), y=as.name(labelY)))+\n",
    "        geom_point() +\n",
    "        ggtitle(paste(labelX,\"and\",labelY))+\n",
    "        labs(x = labelX, y = labelY)+\n",
    "        theme(plot.caption = element_text(size = 8, face = \"bold\"),\n",
    "            axis.title = element_text(size = 8),\n",
    "            plot.title = element_text(size = 8, face = \"bold\", hjust = 0.5))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAADwCAMAAAAeuqOxAAAANlBMVEUAAAAzMzNNTU1oaGh8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\nMMHxMyS9FaoAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(gridExtra)\n",
    "options(repr.plot.width=6,repr.plot.height=2)\n",
    "do.call(\"grid.arrange\", c(plots.cor.high, ncol=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2 pairs below are strongly and negatively correlated together. It indicates that they are almost exclusive.\n",
    "\n",
    "    - MHHUUR(National Health Service) and MZPART (Private health insurance)\n",
    "    \n",
    "    - MZFONDS(Rented house) and MHKOOP(Homeowners)\n",
    "    \n",
    "On the other hand, a linear relationship between MRELGE (Married) and MRELOV (Other relation) is not as narrow as other pairs. It means that they are somewhat exclusive but there would be another factor to describe those 2 variables.\n",
    "\n",
    "Hence, one of the pairs among the strongly correlated pairs could be removed, whereas MZFONDS and MHKOOP should be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the candidates of being removed.\n",
    "cols.cor.high=c(\"MZFONDS\",\"MHHUUR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features having a high correlation with a response variable could be a good predictor for a model assuming linearity among predictors and a response variable.\n",
    "\n",
    "Therefore, it is meaningful to check the existence of those features.\n",
    "\n",
    "Here, figure out the relationship between **quantitative variables** and **CARAVAN (qualitative variable)** by introducing the correlation ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute correlation ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"DiscriMiner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the quantitative cols\n",
    "cols=setdiff(colnames(df), c('MOSTYPE','MOSHOOFD','CARAVAN', cols.cor.capp, cols.cor.high))\n",
    "df.corratio=data.frame()\n",
    "for (i in seq(1, length(cols))){\n",
    "    # calculate correlation ratio and store the result into df.corratio\n",
    "    ratio_=corRatio(variable=df[,cols[i]], group=df[,\"CARAVAN\"])\n",
    "    df_=data.frame(variable=cols[i], ratio=ratio_)\n",
    "    df.corratio=rbind(df.corratio, df_)\n",
    "}\n",
    "# add rank column and sort it\n",
    "df.corratio[\"rank\"]=as.integer(rank(-df.corratio[,\"ratio\"]))\n",
    "df.corratio=df.corratio[order(df.corratio[\"rank\"]),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the all ratio into a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAADwCAMAAAAaeQ59AAAAOVBMVEUAAAAzMzNNTU1ZWVlo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\nArQoQIsCtChAiwK0KECLArQoQIvyP40QCRNKYqj9AAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.height=2,repr.plot.width=3)\n",
    "plt=ggplot(data=df.corratio,aes(x=ratio))+\n",
    "    geom_histogram(bins=30)\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the proportion of the caravan policyholder is approximately 6%, the correlation ratio is basically very low among each variable. However, it is possible to do relative evaluation among the variables.\n",
    "\n",
    "According to the histogram, many variables are located at the first bin, indicating no correlation with CARAVAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Display the best 10 correlation ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 10 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>variable</th><th scope=col>ratio</th><th scope=col>rank</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>43</th><td>APERSAUT</td><td>0.020807805</td><td> 1</td></tr>\n",
       "\t<tr><th scope=row>57</th><td>APLEZIER</td><td>0.011171843</td><td> 2</td></tr>\n",
       "\t<tr><th scope=row>39</th><td>MKOOPKLA</td><td>0.009199731</td><td> 3</td></tr>\n",
       "\t<tr><th scope=row>16</th><td>MOPLLAAG</td><td>0.008194729</td><td> 4</td></tr>\n",
       "\t<tr><th scope=row>38</th><td>MINKGEM </td><td>0.008134808</td><td> 5</td></tr>\n",
       "\t<tr><th scope=row>40</th><td>AWAPART </td><td>0.007984792</td><td> 6</td></tr>\n",
       "\t<tr><th scope=row>14</th><td>MOPLHOOG</td><td>0.007161235</td><td> 7</td></tr>\n",
       "\t<tr><th scope=row>33</th><td>MINKM30 </td><td>0.006372739</td><td> 8</td></tr>\n",
       "\t<tr><th scope=row>28</th><td>MHKOOP  </td><td>0.006159419</td><td> 9</td></tr>\n",
       "\t<tr><th scope=row>31</th><td>MAUT0   </td><td>0.005856772</td><td>10</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 10 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & variable & ratio & rank\\\\\n",
       "  & <fct> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t43 & APERSAUT & 0.020807805 &  1\\\\\n",
       "\t57 & APLEZIER & 0.011171843 &  2\\\\\n",
       "\t39 & MKOOPKLA & 0.009199731 &  3\\\\\n",
       "\t16 & MOPLLAAG & 0.008194729 &  4\\\\\n",
       "\t38 & MINKGEM  & 0.008134808 &  5\\\\\n",
       "\t40 & AWAPART  & 0.007984792 &  6\\\\\n",
       "\t14 & MOPLHOOG & 0.007161235 &  7\\\\\n",
       "\t33 & MINKM30  & 0.006372739 &  8\\\\\n",
       "\t28 & MHKOOP   & 0.006159419 &  9\\\\\n",
       "\t31 & MAUT0    & 0.005856772 & 10\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 10 × 3\n",
       "\n",
       "| <!--/--> | variable &lt;fct&gt; | ratio &lt;dbl&gt; | rank &lt;int&gt; |\n",
       "|---|---|---|---|\n",
       "| 43 | APERSAUT | 0.020807805 |  1 |\n",
       "| 57 | APLEZIER | 0.011171843 |  2 |\n",
       "| 39 | MKOOPKLA | 0.009199731 |  3 |\n",
       "| 16 | MOPLLAAG | 0.008194729 |  4 |\n",
       "| 38 | MINKGEM  | 0.008134808 |  5 |\n",
       "| 40 | AWAPART  | 0.007984792 |  6 |\n",
       "| 14 | MOPLHOOG | 0.007161235 |  7 |\n",
       "| 33 | MINKM30  | 0.006372739 |  8 |\n",
       "| 28 | MHKOOP   | 0.006159419 |  9 |\n",
       "| 31 | MAUT0    | 0.005856772 | 10 |\n",
       "\n"
      ],
      "text/plain": [
       "   variable ratio       rank\n",
       "43 APERSAUT 0.020807805  1  \n",
       "57 APLEZIER 0.011171843  2  \n",
       "39 MKOOPKLA 0.009199731  3  \n",
       "16 MOPLLAAG 0.008194729  4  \n",
       "38 MINKGEM  0.008134808  5  \n",
       "40 AWAPART  0.007984792  6  \n",
       "14 MOPLHOOG 0.007161235  7  \n",
       "33 MINKM30  0.006372739  8  \n",
       "28 MHKOOP   0.006159419  9  \n",
       "31 MAUT0    0.005856772 10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(df.corratio, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best 10 variables are;\n",
    "\n",
    "1. APERSAUT - Number of car policies\n",
    "2. APLEZIER - Number of boat policies\n",
    "3. MKOOPKLA - Purchasing power class\n",
    "4. MOPLLAAG - Lower level education\n",
    "5. MINKGEM - Average income\n",
    "6. AWAPART - Number of private third party insurance\n",
    "7. MOPLHOOG - High level education\n",
    "8. MINKM30 - Income < 30.000\n",
    "9. MHKOOP - Home owners\n",
    "10. MAUT0 - No car\n",
    "\n",
    "Those variables seem to indicate the degree of wealth which customers have.\n",
    "\n",
    "Those variables could be better predictors for models assuming linearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caravan policyholder's distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA, a classification model, draw a decision boundary based on numerical predictors.\n",
    "\n",
    "To draw an appropriate boundary, it is helpful for the classifier if predictors have the properties below;\n",
    "\n",
    "- The predictor value where caravan = 0 and the predictor value where caravan = 1 are **normally** distributed\n",
    "\n",
    "- The predictor value where caravan = 0 and the predictor value where caravan = 1 are **separately** distributed\n",
    "\n",
    "The sample image below showing histograms which normally and separately distribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Figure1: histograms of class1 and class2 (James, 2015)</p>\n",
    "<img border=\"0\" src=\"./img/lda1.png\" width=\"300\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to confirm whether features have such nature, plot histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of numerical predictors is 62, which is too much to plot all of them at once.\n",
    "\n",
    "Hence, predictors having either the 1st or the 2nd nature above are reported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.lda=c('MOPLLAAG','MBERARBG','MSKC','MINK4575','MINKGEM','MKOOPKLA','MAUT1','APERSAUT','MBERHOOG','ABRAND','AWAPART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "plots.hist=list()\n",
    "for (i in seq(1, length(cols.lda))){\n",
    "    colname=cols.lda[i]\n",
    "    tmp.df0=data.frame(X=df[df[,\"CARAVAN\"]==0,colname])\n",
    "    tmp.df1=data.frame(X=df[df[,\"CARAVAN\"]==1,colname])\n",
    "\n",
    "    plots.hist[[i]]=ggplot(data=df, aes())+\n",
    "        geom_histogram(data=tmp.df0,aes(x=X,y=..density..),bins = 30,alpha=0.4,color=\"red\")+\n",
    "        geom_histogram(data=tmp.df1,aes(x=X,y=..density..),bins = 30,alpha=0.4,color=\"blue\")+\n",
    "        ggtitle(colname)+\n",
    "        labs(x = colname)+\n",
    "        theme(plot.caption = element_text(size = 8, face = \"bold\"),\n",
    "              plot.title = element_text(size = 8, face = \"bold\", hjust = 0.5),\n",
    "              axis.title = element_text(size = 8))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **blue histogram** represents the probability density of **the caravan policyholders**, whereas **the non-caravan policyholders** are denoted as **the red one**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8AAAALQCAMAAABoqemGAAAASFBMVEUAAAAAAP8zMzNNTU1o\naGh8fHyMjIyOjo6VlZWampqnp6exsbGysrK9JCS9vb3Hx8fQ0NDZ2dnh4eHp6enr6+vw8PD/\nAAD///8bozD1AAAACXBIWXMAABJ0AAASdAHeZh94AAAgAElEQVR4nO2djXqjKheF7WfamWnn\ndH46rfd/p19MRAFBQFHZ5F3POR2zg+Jy+woaxaZDCIlVc/YKIITWC4AREiwARkiwABghwQJg\nhAQLgBESLABGSLAAGCHBAmCEBAuAERKsIwFummb8+/GjaX583D9ep24TqpRZXp94bZv29cA1\n3ibN783l88cwoQIvn1OxKTKWleZ3Lj3jVy+3jN8+XNqPe+gi2d5NRpb7/3+riU75bK+Tn/fE\nD/kfPuWoPsdCYutqmj/dn9uKf7bPn5/P7efd56+e4BnAf27l9Ynny8e17MuBq7xJmt/+/7/N\nxXT553bgUu7GyFhWmt+5tC3w2vy9Tg1b4OXm+PnyKdveTVaWG+Vx8vlrSnavfmr6tLn6TMuJ\nqqtp37v39p7O372T12GPHo9YnQbwa/PSvOoTP/uZBEnz63Z5b5kGd2aR/o80v3PZW+Aeuxr7\ndZ14vx+Vpcvy2PRN8PDh7rO79B/fx2ReWv3T5uozLSeqrublpXt56e1c7r3GyxLAbfPZtPrE\nRdgJu+b33qr+dAGs3Bkb4lZWmt+5jIxf/g6x381zP/Es3t5NVpavPF9UX/ru8/frvTFu752N\n331qx0/bq8+ylMi6mvfrScD7RKuaeh+b4m76t+9l/OgP0uNEnpOG42T47c9r1Qluo505GO6G\nc4mx7NkOtkrbAr/7M/y/t9i1tfrsarB3k7VX9x9/DyTffV7+3gH++HXraV364Phpe/U5FhJb\nV/P36u2vDfBVYxdS+7fvZd+OVuOEKn7gKm+S5fdXf0DWrss1t2Ow5m6IGGUl+Z1L2wLd3+dm\nuMDTvvZ+6wHYyPL1//YyAHzz+edlSvq1p/Vxb5aHTxmqz7GQ2LquR6pL0zm60MO3xr+3I1Vf\nYpx4Fnbg1vy6ThT+3lI5uhsjY1lpfufStsBVfy/9Pnvd4TuRZ0QeWVm+/v8+9LHuPl9+G7v2\n++3gpT5lqD7HQmLravozoW68iPVb7znbAH/cO5vNxzgxnPnL2aE1v84z/T6Xk7sxu2NZaX7n\n0raA+jyl/2ctF7GMLPf/t7pPddLU3dvcl+avmlFiC/x6ZbZ389lePj8v7acf4PsVvF/Nz3Hi\n2iS1H/dr8jKk+b2fBdpn+m3zOblTkamsNL9zaVvgcsV13AIft1/J2kp+RjKyfD/yNrrPoTt1\nP+u99bjGTxmqz7GQ2Lqaa75+3fdU7UaO8VvtFof+qNZ/e90C40R3v7Hhh5jfVjS/2u0q00Ws\na6JfJncqMpWV5ncubQv0CW/Hax33dui1aS7vJ6/iZhlZHo/Mhs+b/5emnc781acM1WdZCkLo\nFAEwQoIFwAgJFgAjJFgAjJBgATBCggXACAkWACMkWACMkGABMEKCBcAICdZqgP+N0ib/BaLx\nwczzb99Qx67v1vnx+yh+ARi/+BXsF4Dxi1/BfgHYUHuVa7pWv4+W3/r8BgB+sB26Hf+Y07X6\nXdCx67t1/sf1uwzwo+3Qj+Z3Qceu79b5H9cvAD+y3wUdu75b5491VV+PMhHgZMNPd21d4a3z\nx+bX9nv7879ekUsY/EaWLlh75ufrri0LLfoAbe706fOHo5OlFIDVEStph37vJWWHNpK66gj9\n9NZLygFrQZH1rTpAf1030ftbxQAbO0H6/OHoZCkB4HaNYVk79PYEy/K7oMj6VvkF4OTgaefA\nsnboR/O7oMj6ovzaXebCAE7pUUbpyG4nAD+y3wVF1hcH8K1QYQDveBGLFjip6LkAq3NAkX4X\nFFmfXIDpQkdVKGyHVkfltos9Qj8N/pTf/3qJ8etXZH0A7AiWA/CKHdqKCgPYL9+SbYC/9arY\nrxUF4F7WpfiCAD4mwdu8AfA8up9fKwrAvZ7MjfDwAJ/2Q/8Kv7IB3nxnkiyAt/co3UEANnVe\ngtP9igb4oGsc5QCcnt+oVQNgU5ISDMAADMCWJCW4LoAz5dc4BQLgNGsA7Ijul+CKAM53r/tX\nH/wyPy58LkGb8gPApgB46/yRpva61/1Lb3FpgdOsAbAjmi/B9pNi9QCsTW/NLwADcKkJfrqu\n2RsAA7AeBGBTJSZY6ck657M+P33vJfH5ZwBOqM8KArCpkhNMC2xEAbgXAJsqOcFVAbzXve4W\nwPYQMyXnF4DNKACvWt9y/GYB2NgoZeZ3k+zzqGIe6F/QpgQHElRigtWSANiIuvNrP50jAOC0\n+my/tMCGSk4wABtRD8DmRgBgAE6afx7Nl2AANqIAfPMrEOBIrTodKPlWOwA2ogB88ysQ4MgK\naYFvhsyb+6NdFOAXgCNWDYBNlZzgdQCbV2WjXRTgF4AjVu3JHAgNgAtOMAAbUQB2+QVgM8Hj\nEDsFJNg42P4D4AcD+Mt5NgTApmYAvw0AFJDgp2/f9X0RgB8M4DdXKgHYFAAnBwH4GL8A7CoZ\nulf2OIDDozQCsBEFYJffhwM4kODDAI54OgeAjSgAu/wCMAAnBgH4GL8A7CpZLsBzvwBsRIUB\nvHkgewB2lbQT7DonPgFg5yiNT9aIG1EjcnyVd2toJrlvlbU2kr1RTrtVdvsABgDsKjkD+Prp\n+7ezAXaP0kgLbERltcAAnCnBVskyAXYnGICNqHCAk/0CsKskAAPwIX63D2Tv7v3bpwzVj8gR\nGLEBgJODAJyc31UD2dMCT1EADroA4Lx+OQfOleBCAY4YpRGAjejt2Y7/ABiAywA47BeAjajb\nLwADMAAnBQE4Ro8HsNmN7BxdSgAGYDEAbx/IXhjA1lEq28j9ABznogC/dQG82W8cwP9Zoz4k\nWdsP4JYWGICtKABH+E2zthvALV3ofwBsRQE4wm+atf0BTrlzxXOz+/ITAMXc/K5JbToANqIA\nHOE3zdpeAJs3rtACW1YA+F/0Dg3A+fxGA2xdzwJgywoA/4veoe3HRQX5LR3gxvysA3xXcoLL\nBriJ/h18WjfJAKf73QVgK7+C/JYOcG9ZC9nNboUtcBOZ42ndJANs+93+O3/ZAKfnVzzAd8+N\nltC6ATb8RqiCETm8+V3zO3/pAHeR+Y2sr3yAB7Mqw9qdK11GgK13yZzfAgczPK2b1QIPVoS1\nwM2Uz22/85cOcGp+hQM8HqpyGV71uNkJ58DrAR5WXQbAlt8Mv/OXDXB8fpXur07xfx31QL+z\nG7aPTnqYoRSA0/3KBthSht/5nftqYIc+cgePldpyX/3L6/y/cJXeAqcbPg3g5TeeAXCMMvzO\nX3YLnJ5f4QA3ruCi4VCC1zzwHQfwYrMc28VK9isbYMtvht/5ywY4Pb+iAW6UEgwfkeC9AF7j\nVzLAM78ZfucvGeA1+RUNcEqPOrLCogFe41cywDO/GX4mLBngNfkVDnC8IissHOB0v6sAtkbh\nDK9vcnD7ObA1GVlf4QCn51cywM3Y6UgwLBjgVX7XAewKLq1vcnCl3+2/8xcM8Kr8SgY4SZEV\nlgzwKr+CAS42vyX5BWAzCsAOv+H1TQ4CcCa/0gFuYp/giKywdICT/QoHuMj8luQ3APCT83JG\nOQA36r+iErzrVehEv7IBLjO/JfkNAbzGb5o1AF40vOw3/HgdABtRAI7wm2YNgBcNL/qNeLwO\ngI2oMIDDB2jhAN9OGIo7R9rzHNjMr5FV5+N1sgEuM7+H+Y04QEsHOFqRFZYOsKmIx+uEA1xk\nfg/zG3GAfhiAI5XlcTPnQ5h7jDUb8XjdbESOmCfl7JkEKHKHEgyw+wAtHeAi78Qar93v0YX2\n3Nzve7xOeAtcZH4P8xtxgA6MfrSqQdpTIh5mGL/f4yKWrojH62QDXGZ+D/MbcYAW3gKXmeBT\nAPY8XgfARlQswL4DNABnMFwCwJ01Oa0LAGtRuQB7DtDSAS7yHGlHgBfOkboaAS4yv4f5jcjv\nHgDv+SYKET8j7QewrfDjdbIBLjO/h/ldAbA18to6v2/9u6AA+ACAw34fBeBICRuVMnyAngFs\n7mXFA9z3N9KezlnuHZQOcLpf2QAn+xXeAif7FQ7wiqdzesNiAeZppJBf2QBvf5gBgAF45ncc\n0tq7vslBAM6VX6tHCcAAPAfYGNbBtb7JwcMAtm6Kqw9gK7/CAO5if2XwArxHgp0AO++vDBve\n7Fc0wOl+ZwD3qy4G4O35lQZwtKaVswDeIcFugF3BsOHNfmUDnOz3CICXj8Xn5heAARiA1+T3\nJL+SAR7fRLHlHFgQwOv8ygV4lV/BAGfJrySA1edt58ByAF7nVy7Aq/wKBjhLfoUB3LiCy4ZF\nAxzvVynHA/17jEUQp/T8ygZ4xf4MwHUCPFUruQUG4NT8CgM4w89IogDmZ6SQX9kAx/tVsntY\n1ggd6+79vvW49rn3O2BOf2TSHJJzSqhogKM1VSsa4GS/wgHenF9pLbCp2ZMbjhEqALhqgO1b\nCwEYgAFYEsBn5fcsv9UC3JnT08oBMAAv+wXgsgA2x0m2zs+tz1ke+HYu5OCnwn0Jlg1wwdc4\ndvGbnt8sAP/XqwSAS0owLfB2vyWfIu3hd0V+swD8bb+HNwB4Y4IBGIDFAKx3pseVKxVg46H5\n/RJcDcBWhkd/AFwNwHqmz09wEGAdkv0SXCHA5jWO2+nbVOKwaxwHy5ffigA2+AVgy0oVAMcM\no0sLLAhgfRhO36tGADgZYNdA3wAMwGv81vtA/yqAI35WyQGw5VcvujKYBWDnNQ4ABmAxAMdc\nla0XYPc1jqoAXnGALnwQv+0AW79RA7BUgD3XOGoC+KT8lg3wWQneG+DOnPb6lQxwzDUOAAZg\n4QCbP6tkGJGjhJ9NQjo9v1Mm3fk1P8XppAM0AJ8FcO0XsUrO7x5+TzpA73nArgdg630lALxN\nXr81AXxQfmmBowA2747IAXDUzyoADMAAXCTAcT+rALBYgI86QAPwKQBH/qySIcGutxUa84eD\nxwE8/GxYAcCHHaBlAXxUgvcAeM3PKjkAfutHbBAC8A479DkAH3eAlgXwUQneBeBz/ALwQQCf\ndIAG4BiArScEALhcv+cBXIbfZWsPC7C5EAAu1y8AL1kD4PtSAbhYv1H5Ha/s1efXY2IpCMAl\nJxiAXQCraxr1+fWYWArmB1jpiFvPooaVtT9/5X0D4J4JBmAADgRpgUtOMAADcCAIwEUn2DHE\njjF/OJh9h1Y6rYd18EuUd80vAFcO8I4JluCXFjgYBOBHTbAEv+78WoPZVOTXY2IpCMCPmmAJ\nfqPyW5Ffj4ml4AMCbJxXbk+wkrQHvtequPxaEn3Of1eW9a0YYKOOzTrS7/I9DPW1SCUAfKjf\nN/ORvSVnIb8AXKDf5es3Fe7QUfm17nWX7BeAHUEA1j+J8huXX7XXD0st+OV1AAzAABwEWO5F\nSgB2BQFY/yTKLwDrAuD7UgFYjN9VAGf+leFQv/+Zw9aYAuD7UgFYjN91AMvNr9vvuhtXALhE\nv4u5BODbUiXn1+l3sV8NwOITPAqAb0utLb/L/WrvVXcAFuO33nuD4/L7n/EezPryu3jU9l60\nA2AxfgNHaPNTBX4fLb8BgD0X7QBYql9LAFyZX0s+vwAs1m9FtxaS33B+1wGsj31tjINdoOEc\nCZbk17qo809XjX4fLb9xfpcBLuSN5oclWJTfDACL8vto+QXgyhNsX5VdcWeSKL+Pll8AfrAE\n6zw/gt9Hy28+gP/XSxV5KluRmcUvfmX63dwC22dfi9H4YOb5NyUYv7uv79b5H9cvAOMXv4L9\nAjB+8SvYLwDjF7+C/QIwfvEr2G/knVitNi3bMH7xW5Pfza8X7br/hYvsWjRhoVmE32OL4ndJ\nAJws/B5bFL9LAuBk4ffYovhdEgAnC7/HFsXvkjIAjBA6SwCMkGABMEKCBcAICRYAIyRYAIyQ\nYG0A2D9AWLDoQln968WSrV1yaQVyCL/RRfHbub7ew+96gBduDF8qulDM/jqw1ISF5hB+o4ri\n11E2aqkJC9UkG+B2NrGf8BtVFL+OslFL7Vb5PQTgTvs63m+C4QPyi1/8zsuf7/d4gBNOGUJL\nnQ5YR5wiaTXi11Mev3apvf0eBnCki6Slmj2OnTOM33DxcFH8Riwzxe/hAM8/eMvGG45Z6Fbh\nN1zc+cFbFr9LyywM4KR1i1xqu/gxt/AbLO355CuM36VllgVwa07l6XJELzSL8BsqHFMUvxkW\nqusYgFtzMlCy1abjDe+cX/zi1yw7TZ7pN8OdWK027S/ZtlFFE5aqb+0DrlLid7EkfrcudZ1f\n7oVGSLAAGCHBAmCEBAuAERIsAEZIsAAYIcECYIQEC4AREiwARkiwDgW40f9trlL/3qYae42a\n2XzDLDKkuZ08qqkxMha0yoyxw9c7o/SEO9Is3N0gPc9jMs3defJv5D9n7Ydo3C073ZhaDxvg\nZoo00zdyUq65tT12pqPGiExfCTM8l38TNJ2efdEyTTYqaXqGTadZfZ8F8ERrNMCzFrpwbQZY\nmuG5vJvAOHILlwWw8qYntRqAh3XfBLAYzdyuBFiw5gmvpGuhyzRpANxMBXbit2CAjURL7G3p\nbufnwEMR255R+Jz1zihtE4wnvGbvsgLZABv/jQW0Cxtdl+8U+GiAdZ8q4rmI5QRY0lWdmVuj\nHRpTqFvTtkMjz/Bc2ia4fRz29NoA9tBrHLGMXGfsghQAsLUqY7KN67XzFrp4LQPcqSzq9rS8\nCjQ8lwXwcMDOuf8WoBnAqsmdfM4apfFTjtqPUxLA5vcC9+cgwFo+Z4doiYbn8m4Cw6dw+QBW\n35k/GDbGjFlqP06N9b95RLLJvf+rHbyEHbc1p36AJ3uOHVuY4bn8m8DYDWTLNDl0q8z9eNYY\n58vsaQB3+jlgpwLjT90ugIWdEOqJ9V7EsgC2DtmyDM9lHLFrvpHDAtjuP2k7rwqLvIiFEMor\nAEZIsAAYIcECYIQEC4AREiwARkiwABghwQJghAQLgBESLABGSLAAGCHBAmCEBAuAERIsAEZI\nsAAYIcECYIQEC4AREiwARkiwABghwQJghAQLgBESLABGSLAAGCHBOh7gcYDkYfzr5reauIYv\n7cf172vbtK/dNEKyNosgWUbv3j5+NM2P3uM0dTP5o9NKTUaledZlZG385/6nmUb//iHU4WRM\nZU97FdDLZ3fbjYdc+91vX40cC0mrsWn+dH80gC8TwC/Xr7ru+fLR/WpeplHdtVkEyTJ68/bZ\nPn9+Pref+lT/5a9+HxhLjUb/3JYhVHrWlBG1C49/P16EZVVJdzRmrxsCf/rAa/P3OnHpFtxn\n0BkAt+/dezsBfG2Chw8/m1/XAj/7NnkoOptFkEyjd2+vvbc/zas+NaZ1LDUafW1e+hIypWdN\nGZntws2zsKwqzRzpABuBBfcZdAbALy/dy8sEcHtRfenmuS9w0TqQs1kEyTBqeOsPy9OUlvGh\n1Gi0bT6b9ox1zyE9a8rIbBd+ybcrH6uZoxnAl+by11NWOMDv17OA9wng9+t+eye5aT473dt0\nWjHOIkiGUcPblG819X5viq0t0PfEfojtQ2v+RyOOXVhYVgcZjobsNePp0q1P/bs/F/5rl60B\n4L9XYv9OAHftZdjJX5uf3dixNg5q4yyCZBjVvM0BvurewzJK3bvZv28RidL8j0aqAVhzNGbv\n/s39IlY/9ff5dn646H6zzgD42nFsOg3g94HWv92to/E8tkJajtUsgmQYHbx5u9D3GYZSKnLp\nt8TtMohEaf5HI9UAbDrqpfn5ez8TuiJ86fO55H6zTgH4enagA9yNV7RuV3bebxexLIDVLIJk\nGX1VB+Pr0fhVnzJ2gVf1q9pVH8OvDR/nediiyf9k5HbYuh+SRAM8OXIBfN2Ff07RRfebdQrA\nr9f9Vgd4PCH+uLl7bvufkUyA1SyCZBm9eftsL5+fl/vPSGrK2AU+tKP6/ZL0L6l96Mn/ZOS9\neVeGRAM8OXIC3F+2uuL653aEXnS/WacA/OtqSQf46neYeGn6s/7+Ro4fv43rAmoWQbKM3r05\nb+SYZriXGnxfbm3vh9Q+9ORfM/Lzmtqf6mvjX1GaHGnZ0y7cvF/PgvsE9/cjLbrfLIlbDyE0\nCIAREiwARkiwABghwQJghAQLgBESLABGSLAAGCHBAmCEBAuAERIsAEZIsFYD/G+UNvkvEI0P\nZp5/+4Zat8JnRXP6rTe/wUp84dOLTx4AOFeyi4rm9FtvfoOVAPDqYBEJTkp2UdGcfuvNb7AS\nAF4dLCLBSckuKprTb735DVYCwKuDRSQ4KdlFRXP6rTe/wUoAeHWwiAQnJbuoaE6/9eY3WAkA\nrw4WkeCkZBcVzem33vwGKwHguODTXavnD0fXukxI9iz6dVNc2dzRnH5PAnjcKU4D2LVbLnp6\nXIDfelUHcG8KgFcDrHaK8wB+e3u3d8tFTwC8cv5wdK3L6GQDcFoQgDcVnzwAcJ5kA3BaEIA3\nFZ88FHEv9NN7r6ezV2NRwe0LwAAsCeBQdbTAALxpfgBeCE8eADhPsgE4LQjAm4pPHgB4N331\n5wVfZ9RchQ44rwrsRAAcG5QAcGKF/2iBN85PC7wQnjwAcJ5kA3BaEIA3FZ88AHCeZANwWhCA\nNxWfPABwnmQDcFoQgDcVnzwAcJ5kA3BaEIA3FZ88AHCeZANwWhCANxWfPABwnmQDcFoQgDcV\nnzwAcJ5kA3BaEIA3FZ88AHCeZANwWrAIgAOScIs+AKf7BWBvVBjAgdWhBY4NAnDuaE6/ABzr\nCYBXzh+OrnUZnWwATgsC8KbikwcAzpNsAE4LAvCm4pOHcwA2xnsD4PzRnH4BONbTAwGs79sl\nAdxe5ZquFeAYvwAc6wmAY+cPB9cluB3/mNPhZMsEOMrv/gB/qR4ZAEcWnzwAsC4AzpPfRAO3\nLfUGwPHFJw8ArAuA8+Q30QAApxafPACwLvcO/b9e6VtIwJA6Wf2u121L2ZuKIXUWwpMHANZl\n79Dtg7XATr+0wLGeigR4SmnGq5QSAO79PlIX2usXgGM9lQiw9iuDnuxHANjnt1aAM+Y30QAA\npxafPAQA1o7JjwYwF7HSVwCAk+LHdqH3BPi/XgCcL5rTLwDHepIC8ParlNYF2qfvvUp48FKd\n57fa9F3B7SsR4Ci/ABzrSQrA2xNst8DfehXQAq9PtiPqfz10OQDH+AXgWE8AHDt/OFgCwHNT\niUtYH83pd3+An9SxDoAji08eADhPsgE4LWiyqvIPwJHFJw8AnCfZAJwWLArgL+PxVn0NANgd\nBOCdozn91gSw+0Ld143UqgHOfJUSgHeO5vRbEcCeRqhqgHdJMABvinqvbwPwsgA4U4IBeFP0\ntmcBsP4pQQC8PcEAHBt1NrYAvBlg42Yk5+OMDOy+EATg2OiTqxEA4A35fbSLWLskGIBjowAM\nwI7w5AGAk/0CsDeaFWD1hEve/OoPT6q5ATh2JQQDnK6nHE9oPLlOw5xBwXI+zLLPEy46vwC8\nVF1tACdW+I8WOH5+dwvsCvqWGuvK4BeAl6oDYACOnf8wgNvWuBtJzQ3AsSsBwElL+AfAx9wL\n7QHYMc7EoicAjp0/HATgbH4fF+Bv3757MgjAABwXBWAAdoQnDxbATTTQoepkALzGr2SAD8pv\nOHgQwMt+1dwVAdxbjstxqDoZAK/xKxngg/IbDh7WAi/5VXNXBfDdczjJoeqkAJzuVzbAh+Q3\nHDyyC+31q+auCuDBbDDDoeqkAJzuVzbAh+Q3HDy6BXb6VXNXBPB4qHoQgNf4lQzwQfkNBO0h\nbA44B34UgOMVqk4GwGv8Sgb4oPwGgn3639+OADjOIwDHrgQAJy3hHwADsDM8ebC70K5g/gQX\nA/Aav9sB9oyCeEQX+pj8BoLHAbzsV1ufOgBulCISvEmFvFolxW9w+6YA/O5868ruAK/zKxfg\nkF9tfeoAOKVHHapOUguc5vdYgF23425tgXfPbyB4dAsc8lgRwPEKVScDYFv6wypbX26WB2DX\nPpTvHDjGr2SAl6WtTxUAN2OnI8G8YIDnfrO+XrQ4gFf6FQtwcH/W1qcKgJMUqk4AwHPVDfBK\nv2IBDkpbHwCOWglxALv81gxwpvwGggC8tfjkwQa4iX1iJVSdEIBNv+YOrc4JV77Q3D8mlmcc\n4uiFbBgTa0e/8bL97zgm1uL+rPaOigBu1H9BhaqTAbDl19ih266+LvQav5Jb4OX9WVsfAI5a\nCVEAa9PdIwDs81svwEq+NzOcdHtCkgAYgAN+6wVYW59aWuDbCcNDnQMbfqsHeI1fyQAv78/a\n+lQDcLRC1W0B+Mn3/sz8AJuqH+AVfkUDvChtfQA4aiViAX7z7KF7AzzejbT0QvPtAHsOUMcD\nHOUXgCONFgHwMXdiGTvwqQCf8jDD03fnV8d0oQt4mME+gO3ahX6sO7EOutnd2LfPBPichxnO\nA7iMhxn6LfP92xEAP9zDDAAc9gvA3igAJ8UBOLr+dQl2+wVgbxSAk+J7AHzQOXAxAD/YOXAZ\nD/QfCPCjnQPHK1SdDIDX+JUM8EH5DQSPAzjOIwDHrgQA378BYADeVHzy4PgZ6YA7scoBeIVf\n0QAfk99A8ECAF/2quSsC+KB7oYsBeI1fyQAflN9A8NCLWI91LzQAh/0CsDcKwElxAI6uf12C\n3X4B2BsF4KT4TufA+lV3e9TCTDe7FwOw7devxAptk+Y3J99KmeZXMsDLftXcNQFsynhCxRw0\nKVSdEIB3lH9InYQnxXMPqVOEbP87DqmzKLV3AHDsSggGOLFC26T5DT8j8TPSpuKTBx3g8U0U\n/hEbMiW4DIDnfmOS7XytkWs1igN4lV/BAAf9qrlrAVh99ozY0OYbtfBpuQt16yIe00c0/S5I\nbbov81HWha1eHMCr/AoGOOhXzV0RwI0Z3GvEhjJa4LnfBakl7Qews22PB9h8xjqbX9kAz/3q\nHUk192MAbNkPVQfAyQC/O8bZSQC432gAHPDbVg6wddm9eoDTf1aRDfCj/4zU1t4CW6q+Cx0v\ntSThACf7FQ7wTI8NcK5BzwAYgM8F2LgQW9HA7rZ2GrUQgAGYFviAFnivBAMwAAMwAMfXv9al\nJ9kAfD7AUT+bzQXAORIMwI6vnKO9A/cTqqYAABk5SURBVLAX4P7lAAAMwIl+dwT4uysIwAA8\nD08eADjRLwAvRAE4KV4vwP/1OgNg+/lnT7KrATjstzaAdY1Vud9VBcDeYAhgK8FxC12KRpqK\nuHGlKoBPejthcQC7SQXgf+oO/S+rKAADMADLAPjNfJPoXRIA7sxptSQnwJ4HiXYD2HWGsRVg\nj18AjjYKwP+0rwsCeH7bnX3XnTOYOqSOe/Sc+OCKZ6gj/O6hLEPqZBhXSNvfANhTm2SA4y9i\n3d5YfWAL7No8RrOczy8tcLRRAP6nfV0AwF18F7oEgPuNRhc6RVpVAOypDYAdAmAA3lZ88gDA\nutZeha4BYHFXoVecMljSqgJgT20A7BAA5wDY2IdWSasKgD21yQI44vnnqgDe63lvK/hl/cwG\nwFuLTx4AONFvXQBvzm9U0NwJAHh78ckDACf6BeCFKAAnxQE4XP/M8Fa/ALwQBeCkOACH658Z\n3uoXgBeiAJwUPxXgSLkH/Au9WqXA4QDVpnM+eQbAi0EAzl188kALvCbZAAzACWEAXqwKgMfq\nAHh9TgHYWVsWgMcREwDYvw4AvFqeU7YSz+RmkgHw23DfKwD71wGAt+WUFthZ22MA7BkRFoDv\nwSwAWwNXnQawZwAtv39//HEAVoPcFQuwDo8eBOB8AKuj+LDU0wB+04c+ifDvj0sA2DxerQV4\nsTcFwPN1yOcXgO3ogwH8zWRViwKwIwrAviAAA3AObRy5avom+5hY5V4yte/mWTUm1m0MrHdr\nphPGxALgfyIB1taFFtgX3bUFNkf7pwW+Sy7Ayz8OA3Amv6sAtgYDzwOwuZMA8F2CAV78bQmA\nM/ldB7D504P9ywsAby0+eQDgNckG4DSAV+UXgP3hyQMAr0k2AANw9EbxxwEYgD3rkM8vANtR\nAAZgAAbgTcUnDwC8JtkADMDRG8UfB2AA9qxDPr8AbEcBGIABGIA3FZ88CAbYekTJftzMXJvN\n0tYFgH3RMb/mEyx1Afyf6+3MCxvFH39wgO0EWze7m2uzWVq1AOyL7prfUgD+5kr2wkbxxwEY\ngD3rkM8vAM+jAAzAAAzARwCsv/Bq1cuvDgTYelrFXJtIhf3WBfDm/H5Zzy04rJcE8EJOqwR4\nxesnVUKPB9hKsOk9Mr9hv1UBvP31onmGTDoK4KWcPirA1psjx18QTgfYbBrSEwzAN9n5VQJg\nh0QC/PauP+r5z3pK90SAjT0rPcEAfJOdX7uHtduYZ8IAXhqssjSA/9dLFXkqWvZLmRISLNJv\n4hAzj+tXkkdNc0vZz4EXo/HBzPMnJ3jBb8oKnxXN6bfS/Mbk9Lg+cWLxyRIAJ/stC1V3NKff\nSvMbk1MAXh08P8EAnL4CkvIbk1MAXh08P8EAnL4CkvIbk1MAXh08P8EAnL4CkvIbk1PxAI93\nrrTadMUJjvJbFqruaE6/NeY3MqfyAY7R/8JFdi2asNA9lbIaJZTdY6Fy85tYSTnFATiXSoAS\ngNeqHCITiwNwLpUAJQCvVTlEJhYH4FwqAUoAXqtyiEwsngFghNBZAmCEBAuAERIsAEZIsAAY\nIcECYIQEawPA/gHRgkUXyupfL5Zs7ZJLK7C7EuuPLpuy3Mzb4IHym5q95JXZb+nrAV64EX6p\naMhLa00uF49c6O6KWFWjeGzRlOUmrkPK4irPb2r20op3CflOX7psgNvZxElK2+ptdNEHB/ig\n/O4NcHy+05d+CMCd9nV8fhMSfDa/dyVQmQRwStlTAO60ryXmd82WS0MyFeB4HQ9wwilSaKnT\nAfrsU+D7WsSXiy8ab6wQgAXmtzCAyzsH1r9N6I0lJDhc//5KAS26bFrhnHv5A+V3xeITm9SU\n4mnlDwd4/sFbNj7BMQvdXZH1J+0tKYXPbYEl53dXgFMXnlj+KICTchG51Hbx49FKaSejm0ox\nAIvOb/qWS2pR004AygS4NafydLGiF3qE9jmASwFYdn6TF5+8KtJb4NacDJRsten4BEvitzaA\nhed3VS83vYaEokcAvDAgmqvkeG4eeVNPTNHpn7OvQid2k+ITVMCdWA+Q38TkpV8UT2reD7oK\njRA6XQCMkGABMEKCBcAICRYAIyRYAIyQYAEwQoIFwAgJFgAjJFjHA9xM/zbq0zhx+6e5qhv+\nvU021qxCZDpVEeXO9tlppZrZMgTKzJr5t7E9C9TgZTQy7q2NkVij8PB3sp9pLY5U04z/NOqT\nTnLXGBPWLJJkOu0sd7ZPx9HMZFmajKw1mmdjUqw/25GWMyOyaD/HahwtC2C1C9vYGptEZrJt\ngJ3uZtyah67KARbs73EBHnZRB8CWs8YxiySZTg13foDNbSDOsyYja949WKy/WICdhWsC2PjP\nWCPtHLgCgA13XoDNbWC0xtKkZ03/vw6AZ46sKza37/QzYLf9LOtxrBSQs/8aw7l1TBvbMUEy\nnGru1Ffj1HRBxywlHWCz91EpwLOrccYFqvEaT8UADx+bWWJrAtjrzvBpl8p3sfIEGfZnrZNw\ngGe/kJgTmqtl+9tXJNNykmp0AqzWpk6Ah88BgOelOnGuR9n2jQnxAKu/boDN9nbBfqYVOVJa\nd2Lcsw1v9m5s90DEyHTaWe48Pu1Ed+JsK032NSPGjq39I0yTowiAl+xnW5Pj5ADYbJDcN3LU\nALDhTvOpz3D7x+w7C7Ot5ATYvLDTSTXnAth5Ecu+D8m2n21NEEICBcAICRYAIyRYAIyQYAEw\nQoIFwAgJFgAjJFgAjJBgATBCggXACAkWACMkWACMkGABMEKCBcAICRYAIyRYAIyQYAEwQoIF\nwAgJFgAjJFgAjJBgATBCggXACAkWACMkWAcDPL4LeRg09/mjG98lc/vn5fM+zvv9z8ePpvnx\n0RlT3WvbtK/HrvYW6YNcj3Z7m9pXv4fB7a+6/DlzZTPoburSXB1eE9V1n82lM7fCD63cuDka\n2e+ROU3HA/yn+zPw2nV/++RO45x3169+aAB/ts+fn8/tpz7VPV8+ul/Ny7HrvV5/bpYtuzeb\n2lcXBXDX/Wg+Tl7jbRpM/bj++bhOfty96lvhl2VebQ5x738uQocD3L53763aW8fdtuvsQP/n\ntW+a/jSv+tTPfkqQXpuXfrUd7rSvrp6mY5qg3oVDg6n35ueV1Kb5dU3Yu2MrOCIAvEaHA/zy\n0r28THvrzyWAL/e8XuZTctQ2n31H0rJ7+zN91V4045dT13erBlN/r32kH837tWl9af6aW8E2\n3wHwBh0O8HvTXf8fz4E/9XPgoXvV6BG9ldbbayHqe4d9d1K3O9jUvnpvfpuNs1hppq6MdldG\nVR9ZRa+N86sV+UUXerUOB/jvdV/9O/H6rLfA/eWMbta5nk8JutjR9/1/q4Z3sDvY1L9qL5UA\nPJp6vub55fr3T+9Zs3rVa2dH7lc0ZDs/SYcDfO0iNmZHWetC/+2zvdyFfu4vb8rJ9e1q7Hip\nbrB7t6l/9T71OG4dS7EaTb1e8/zzegJ8O9M1t4JRbtwcgpJako4H+NJcvADfrn1YF7F+jxex\nft+vjvzu5OT6Yzgd+DDt9jbNr8bren9EX8SaTP0ef3D4ZW+Fzt4ut6zLSWpROh7g1+seqvbW\nG5LGRay2+dR/Rrp8fl7uPyOpqe657X9GEpLrn9fdt+86/7TsXm2aX73X8TPSZOpj/Mn/w9oK\nZrkx6wC8SscD/Ouau/Ei1o/OvIh13ZFftFNB740cP4T8lnS54fhx63SMdrubTf2rrt+H71vi\nWfSNHJOpq6H7eUJjbgW73Jh1AF4lthlCggXACAkWACMkWACMkGABMEKCBcAICRYAIyRYAIyQ\nYAEwQoIFwAgJFgAjJFibAf43SptcjEUXzDjzVm/udfGGTy++Nasr8rpzaLnYdr9SBcBR3k4n\nMrH41qwCsBQBcJS304lMLL41qwAsRQAc5e10IhOLb80qAEsRF7EWFNil/OHTi+f0DsAlixY4\nytvpRCYW35pVAJYiAI7ydjqRicW3ZhWApSgXwF83RWWiGoCf7opdS3+4ZIDdiQXgUpQN4Le3\n97dHA7j3/FY7wL1HAC5WABz25quiaoCVvt6v+sq3PJRXABz25quiaoDVkmiByxYAh735qgDg\nA0MA7BYAh735qgDgA0MA7BYAh735qgDgA0MA7BYAh735qgDgA0MA7BYAh735qgDgpJDvV3MA\n3iIADnvzVQHASaHr5nJuLQDeIgAOe/NVAcBJIQDeQwAc9uarAoCTQgC8hwA47M1XBQAnhQB4\nDwUAbq/SJm8fWi0IwAAcGwLgPbQMcDv+0QKtUWTYglUCHNBTf5vw+9Muyz5dassBcNlKA3gG\ndN0AB6qgBU4KAfAeSgfY5DcSYOOpUgDevfg6vy7vAFy2kgC+fxxPgf/Xa/gq8NSZzIfSArsU\nACeFAHgPrQDYjA1bMNQC98mjBS4N4La1r1LOvANw2UoH2JoatiAAh1e9PICNXDqvbQBw4UoB\n2L6addOwBQE4vOplAuxKbwfAUpQOMF1opboAdl+cBODCtQ5gLdnDFgwAbDyJAsC7F4/3OGXX\neXEy4+XHp4p/NT9PkXdi6SQb1zpiAf52FQAXDbDxiRZYiA66FxqAl8JFAGx9UksC4LIFwGFv\nvipqALj1fVRLAuCytRPAX8OtVwAcEy4CYLrQIrUXwG/3y84AHBMuBuD5tQ0ALlwAHPbmq6Ii\ngNVjonPvAFy2ADjszVdFDQAHvQNw2coFsDXkIAA7BcAAnFnZAP727fs3AF5cdQAG4OwC4LA3\nXxUAnBQC4D0EwGFvvioAOCkEwHsIgMPefFU8/dcLgCNDALyHANiQ+6cUTxU3z98AODIEwHsI\ngHV57kbyVAHASSEA3kMArAuAZ94BuGxtBnjQ0/erpoc9b0+Rao+RWl8XLQDWvQNw2aIFnukG\nsPFQu0e3o5KUw1KqpkwCcMkCYFtcxDK8A3DZAmBbAGx4B+CyBcCW9CfcA1VUDbASY2KVLQA2\nZYxQMbox3gwzqmqA1ZJogcsWABvyjY3s3IsfAmDrMTP/GgDwKQJgXa3v9SIPDLDTIwCXIgAO\newNgAC5WABz2BsAAXKx2AvhpOHUC4JgwAEcYBGCn9gL4251YAI4JA3CEQQB2CoDD3gAYgIuV\nBXCTDLTKjkyAl/2quesBOD6/akkZAfYMfwDAWzRLaJPIsMqOTICX/aq56wE4Pr9qSRkB1veB\n5GUBsFuubDYpEE/ZkQnwkl81d00Ax+ZXLQmAy5avBU7taokFeMmvmrsmgGPzq5YEwGXLdw48\n/KvfmKTuUnKOGyUUYNuvKTV3PQAv+3V5B+CytZxIY4iZ1hGTDvCy1Nz1AJzuHYDLFgAvSM0N\nwBFrAMCnyO5Cm0Ed1tYR66QDbPm1pOauB2Dbr/7whntIXQAuW8a+2yipgAGwOgUeY/q4Udao\ndfZwUWUOajfza0ntHrUAPPerEesZkROAy5azBR41a4HbjC2w8aTpqS2wT2ruWgCe+wVg6Uo4\nBx6m8wGs31rHOXDW4pEGW3sagKWpMacXutAqUA/Ac7+W1NyVAOzIr34KPP4xhtTNd/JT5mmU\ndMW3wPm70GcDHJSauxKA4/JreacFLltpALcdAE+SD/CUZAAWKhvgxnxiRXWx9Duwct2JVQTA\nll+37BfFDJL4ZgaHXwCWrPlV6CbtIeEpOxIBXvar5q6nBbb80oUWLwB+dICXb9AB4MIFwI8M\nsPMUyfQOwGVrdg6cyK9wgJf9qrnrATg+v2pJAFy2ThwTqwiAY7zVBHCydwAuWwAc9gbAAFys\n5l3opAF1xAP8SHdiJeVXLQmAy9bywwwRmrKTDLA+SuF5F7HC3ioCOHmsMwAuXGcCvOYZYQCO\nKr7Or8s7AJctAA57G18UYwmAk0IAvIdmg9odeA5cAsBR58AeUiUCzDlwZTrzKnQBAEd5qwjg\nNd4BuGQBcNgbAANwsXL8jHTYnVglALzoV3NTC8DR+VVLAuCytfle6EErBrUrYYSGuHuh6wE4\nPr9qSQBcts58mKGAFhiAA3kF4MIFwAC8KMbEKlvOWylTFjDsMUIBXvaruakE4Pj8qiXRApct\nrkKHvdUE8ArvAFyyADjsDYABuFgZ40KHXjXi0pQdcQAH/WpuagA4Kb9qSQBcthyjUj7W78C2\nX30Ye81NDQAn5VctCYDLlvNhhgdpgV1+27oBjs+vWhIAly0ANvy2lbfAAFyb+BnJ8ls3wPyM\nVJvKuQo9f+b2CIBnGgCev+Brfg+CxDczRGvKJACXrIIA1ofI8qbxKIB1bzW1wKl5BeDCBcCW\nANj2DsAlC4AtAbDtHYBLFgBbAmDbOwCXrADA+vty9NeLZnk/MADvVjzer09qSQBctpYBdr5+\nsjWKTNkB4MCqAzAAZxcAL0hzUynAdg+L14tKUzzAKmDyC8CSATby6zwwA3DhWgHweKDWb3bY\nPibW0/tVZd0Voe16ABxaAwA+RWkAt/PYlB1a4MCqlwfwlGRfzwqAC1c6wOYEAFcDsLNnxZhY\nhSsJYNfUsMcAcHCN/OFTATZ60FzEkqYUgFtHDIBrAdj6oJYEwGUrAWDtXElL+pQdAA6sepEA\nt55PakkAXLYi78RSV59bLXbXlJ2tAOvv+/amEYCjikdbtM6KAFiaCroXepZfAF5dPNah6xcG\n2zsAlywADnurF+CpV9V5elYAXLgAOOytXoCjvANwyQLgsDcABuBiBcBhbwAMwMUKgMPeABiA\nixUAh70BMAAXKykAj4POAjAAz0Pb/UqVGIDVfVoADMDz0Ha/UgXAEWJg94gtDsCnCIDD3miB\nAbhYAXDYGwADcLEqFuCvm6YFAnBK8a1ZBWApKhfgt7f3t2WAn9SlaQC2w1uzCsBStBngQRkG\ntTM/fvVj3H1N3zqGvLvF9hwHT9v1ADi0BgB8ioptga23jTpb4LchSAtsh7dmdRJjYpWtcgG2\nFgjAKcW3ZpUWWIoAOOwNgAG4WAFw2BsAA3CxAuCwNwAG4GIFwGFvAAzAxQqAw94AGICLFQCH\nvQEwABcrMQCrUaMBGIDnoe1+pUoMwOpbAAbgeWi7X6kC4LA3AAbgYgXAYW8ADMDFSjTA/w0n\nxgBsh7dmFYClSDTAQyUAPAtvzSoASxEAh70BMAAXq5oANp5APA3gL2ssEWM1nFEAjjEIwE5F\nvh9Yn97r/cDbAdZfEb4OYN8b+hIAfrKeZDZWwxk9EWBXfm3vAFyylgHWX/o8vuhbi3UlA6yD\nFLk1vC+5TgG4X6nvMgB25XfmHYBLVlUAq7u15guM3BoA7PAOwCWrKoD9C4zcGgDs8A7AJWsL\nwP/rNZR8KlVJW8PtrVxzMyW59QEsyHui3wqVqwWOP2zGF8w4c+TW8Ho7/XehxOIr/G7N684h\nWmC3ANjntwNgf20AXIoA2Oe3A2B/bQBcigDY57cDYH9tAFyKANjntwNgf20AXIoi78Rq9Wnn\nHTtVAOz1djqRicVT/er5XZlXAD5Fud6NdNX/wkXSCmZf4AYlVlFU8Y2KrC2uWM5SB2+HMgXA\nu1RRVPGNAuCSBcC7VFFU8Y0C4JIFwLtUUVTxjQLgkpURYITQ0QJghAQLgBESLABGSLAAGCHB\nAmCEBCsDwP6B0QIFfSX175YW2NoF/VVvVOKy01dl36WvU2Reo7PqnGO5lKdY9B73ANoO8MIN\n8f6Ci3tsa00uJihmgVsVXostxfvCCaXTl75OkXmNzaqG3EJJbUMsNARxa/YYkg5wO5vYQXsD\n3KaUlglwa2XKtzAATtSBAHd2weUicQs8ogFetZekIZkK8AFaAXBUVyniKB9cVtSaPYbOAjj2\nFDiwwKizr80qDOBjzvrWABx1dhsJcCChAHzXwQDHgJmywLi9YqtWLDyxSU0pnlh+rda2wHFt\n67ZScTvSQ+gkgOcf3AWjAQ4ucIt2BTh14UftsisA7vzFkgFeXBYAjzoW4Hje4hbYLn7MpvS9\nJKlFTev+A3D0wh5BhwLcmlPbu9BxC9ys5IUnr0gdLfBhXeiD8i5BRwLcmpNL2YnsIZmJ3C2P\nq3q56TUkFC0X4I2NplEqopkG4O2L8A+MNi83XoEJFYxZoLnj7HltNm3hiX3i2yy7rcx6RaYh\nOv1drlLRO9IjiHuhERIsAEZIsAAYIcECYIQEC4AREiwARkiwABghwQJghAQLgBESrGMBbqZ/\nm5s6NWFEprJDxDMlQ4Md06/xlfrbSLPmVDP+MTJ5n5ybN7Iv3/3ROhjgZvxn2mvNVdG/0lLv\n+iNDjbVHGzv1cJTSvxJkzalGz9zoyN4K7ghKVtEAT4dq15QQRQCsdnm92RKrGbVeXAE4g47u\nQo953QiwHAGwFQXgnDoP4Pk5sFohKyIbYLULO87wtf8bzZs0h6ZMY80sMi+jIsKNn6SjAR6b\nX0cLPNvFfQBLutox21GnizVVA6wfrB2HMUdEuPGTVBLAXTdlO9SFlpJsR/+iUzb1r8zTCrlq\ntMOw9tfqU83M32NnrLB0FQaw1Vh1S1MiZHlpfDarAXj8awCsos2snHnIRqk6HGCt09g5cmqe\nFjXd0h8BasZ/Z3us9VXTCLPmVKP9a6Wxm7bC3LwRRAk6D+CFi1jTmkm/kUPbUe0zfBfbkqw5\ntRLgCg5dZ4mNhpBgATBCggXACAkWACMkWACMkGABMEKCBcAICRYAIyRYAIyQYAEwQoIFwAgJ\nFgAjJFj/B1B+Hkwakw9LAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width=8,repr.plot.height=6)\n",
    "library(gridExtra)\n",
    "do.call(\"grid.arrange\", c(plots.hist, ncol=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there are no predictors whose each class is exactly normally and separately distributed, some are either normally or separately distributed.\n",
    "\n",
    "These 11 predictors would satisfy the nature required to contribute to predicting.\n",
    "\n",
    "1.  MOPLLAAG - Lower level education\n",
    "2.  MBERARBG - Skilled labourers\n",
    "3.  MBERHOOG - High status\n",
    "4.  MSKC - Social class C\n",
    "5.  MINK4575 - Income 45-75.000\n",
    "6.  MINKGEM - Average income\n",
    "7.  MKOOPKLA - Purchasing power class\n",
    "8.  MAUT1 - 1 car\n",
    "9.  ABRAND - Number of fire policies\n",
    "10. AWAPART - Number of private third party insurance\n",
    "11. APERSAUT    - Number of car policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Logistic Regression\n",
    "\n",
    "    Logistic Regression would be an appropriate model for this task. This model can provide not only the probabilities of occurrence of the event, but also coefficients denoting how much contributes to making the probabilities. This information helps to determine what kind of customers should have a mail from an insurance company.\n",
    "    \n",
    "    In addition, the exploration data analysis shows that there are correlated features with CARAVAN. It indicates that Logistic Regression can hold predictors contributing to the prediction.\n",
    "    \n",
    "    On the other hand, the exploration also detects the existence of multicollinearity between features. Logistic Regression cannot estimate parameters when predictors are strongly correlated together. Hence, one of the correlated pair should be removed for this model.\n",
    "    \n",
    "    In terms of the number of features, it reaches to over 60 variables after removing correlated ones. In addition, the exploration also finds that **many features have no correlation with CARAVAN**. Therefore, it is assumed that many of them have no coefficient. To efficiently and effectively select related features to purchasing the caravan policy, **automated feature selection** should be considered. It is possible for Logistic Regression to introduce 2 ways of feature selection, which are **subset selection & Logistic Regression** and **Lasso Logistic Regression**.\n",
    "    \n",
    "    In conclusion, 1. subset selection & Logistic Regression and 2. Lasso Logistic Regression are adopted.\n",
    "    \n",
    "    \n",
    "2. Linear Descriminant Analysis\n",
    "\n",
    "    This model is not very appropriate for this task since it does not provide information on how much and which variable contributes to the probability of the event occurrence. In addition, LDA cannot deal with categorical values.\n",
    "    \n",
    "    However, the exploration recognises that several features are normally and separately distributed, which satisfies the assumption of LDA. Furthermore, the exploration demonstrates that in the histogram plots, categorical values do not show any patterns which are helpful to find the caravan policyholders.\n",
    "    \n",
    "    In conclusion, LDA performs based on different properties of features. Therefore, introducing this model could provide a good model comparison with Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dummy variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with categorical variables in the prediction task, convert them into dummy variables.\n",
    "\n",
    "Categorical variables are `MOSTYPE` and `MOSHOOFD` which have 40 and 10 levels respectively.\n",
    "\n",
    "From those 2 variables, generate 50 dummy variables.\n",
    "\n",
    "After that, remove 2 duplicated variables and 2 original variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"dummies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOSTYPE=as.factor(df$MOSTYPE)\n",
    "MOSHOOFD=as.factor(df$MOSHOOFD)\n",
    "df.dm=cbind(df, dummy.data.frame(data.frame(MOSTYPE, MOSHOOFD)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop duplicated and original variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dm=df.dm[, -which (colnames(df.dm) %in% c(\"MOSTYPE\",\"MOSHOOFD\",\"MOSHOOFD10\",\"MOSTYPE41\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, there are 132 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "FALSE"
      ],
      "text/latex": [
       "FALSE"
      ],
      "text/markdown": [
       "FALSE"
      ],
      "text/plain": [
       "[1] FALSE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"MOSTYPE14\" %in% colnames(df.dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the previous exploration points out, there is no value of 14 in the categorical variable of MOSTYPE.\n",
    "\n",
    "Hence, the dummied variable `MOSTYPE14` is not generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset selection + Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove highly correlated independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use dummied data frame.\n",
    "\n",
    "According to the previous exploration, remove the features highly correlated with another independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"There are 109 variables including CARAVAN now.\"\n"
     ]
    }
   ],
   "source": [
    "cols.subsetbase=setdiff(colnames(df.dm), c(cols.cor.high, cols.cor.capp))\n",
    "df.subsetbase=df.dm[cols.subsetbase]\n",
    "print(paste(\"There are\",length(cols.subsetbase),\"variables including CARAVAN now.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build a model for subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(leaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit.glm = glm(CARAVAN ~ ., data = df.subsetbase, family = binomial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Investigate the warning message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This message occurs when there are separations and quasi-separations among predictors.\n",
    "\n",
    "As the left-hand side of the picture in figure 2 shows, separations mean that one predictor (X) can perfectly determine the class of a response value (Y). Similarly, quasi-separations also do the almost same decision with a little overlap as the right-hand side of picture shows.\n",
    "\n",
    "These properties of variables affect on estimating parameters for Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Figure2: Image of Separation and Quasi-separations (Minitab, LLC, 2019)</p>\n",
    "<img border=\"0\" src=\"./img/sepa.png\" width=\"400\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the features having separation or quasi-separations through the equation below.\n",
    "\n",
    "The maximum value in a predictor where CARAVAN = 0 $\\le$ the minimum value in the predictor where CARAVAN = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=setdiff(colnames(df.subsetbase),\"CARAVAN\")\n",
    "cols.sepa=list()\n",
    "for (i in seq(1, length(cols))){\n",
    "    sum0=summary(df.subsetbase[df.subsetbase[,\"CARAVAN\"]==0, cols[[i]]])\n",
    "    sum1=summary(df.subsetbase[df.subsetbase[,\"CARAVAN\"]==1, cols[[i]]])\n",
    "    if ((sum0[[\"Max.\"]] <=  sum1[[\"Min.\"]]) | (sum0[[\"Min.\"]] >=  sum1[[\"Max.\"]])){\n",
    "        cols.sepa=append(cols.sepa,list(cols[i]))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extracted variables are;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'AVRAAUT'</li>\n",
       "\t<li>'AWERKT'</li>\n",
       "\t<li>'MOSTYPE15'</li>\n",
       "\t<li>'MOSTYPE16'</li>\n",
       "\t<li>'MOSTYPE17'</li>\n",
       "\t<li>'MOSTYPE18'</li>\n",
       "\t<li>'MOSTYPE19'</li>\n",
       "\t<li>'MOSTYPE21'</li>\n",
       "\t<li>'MOSTYPE28'</li>\n",
       "\t<li>'MOSTYPE40'</li>\n",
       "\t<li>'MOSHOOFD4'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'AVRAAUT'\n",
       "\\item 'AWERKT'\n",
       "\\item 'MOSTYPE15'\n",
       "\\item 'MOSTYPE16'\n",
       "\\item 'MOSTYPE17'\n",
       "\\item 'MOSTYPE18'\n",
       "\\item 'MOSTYPE19'\n",
       "\\item 'MOSTYPE21'\n",
       "\\item 'MOSTYPE28'\n",
       "\\item 'MOSTYPE40'\n",
       "\\item 'MOSHOOFD4'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'AVRAAUT'\n",
       "2. 'AWERKT'\n",
       "3. 'MOSTYPE15'\n",
       "4. 'MOSTYPE16'\n",
       "5. 'MOSTYPE17'\n",
       "6. 'MOSTYPE18'\n",
       "7. 'MOSTYPE19'\n",
       "8. 'MOSTYPE21'\n",
       "9. 'MOSTYPE28'\n",
       "10. 'MOSTYPE40'\n",
       "11. 'MOSHOOFD4'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"AVRAAUT\"   \"AWERKT\"    \"MOSTYPE15\" \"MOSTYPE16\" \"MOSTYPE17\" \"MOSTYPE18\"\n",
       " [7] \"MOSTYPE19\" \"MOSTYPE21\" \"MOSTYPE28\" \"MOSTYPE40\" \"MOSHOOFD4\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "as.character(cols.sepa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "\n",
    "There are 11 variables which could affect the modelling.\n",
    "\n",
    "Keep them and confirm whether these predictors are held or removed by subset selection and Lasso Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Run forward feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set nvmax = 100 to save execution time. It is not necessary to know 100th and more variables being selected.\n",
    "regfit.full=regsubsets(fit.glm$formula, nvmax = 108, data=df.subsetbase, method = \"forward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Store the selected variables into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate df based on the outcome\n",
    "tmp.cols=summary(regfit.full)$which\n",
    "tmp.cols=tmp.cols[, -which (colnames(tmp.cols) %in% c(\"(Intercept)\"))]\n",
    "# convert the df above into a readable df\n",
    "cols.subsets=data.frame(matrix(rep(NA, 2), nrow=1))[numeric(0), ]\n",
    "colnames(cols.subsets) = c(\"ord\", \"variable\")\n",
    "for (row_ in seq(1, nrow(tmp.cols), 1)){\n",
    "    for (col_ in names(tmp.cols[row_, ])){\n",
    "        if ((tmp.cols[row_, col_]) && !(col_ %in% cols.subsets[,\"variable\"])) {\n",
    "            cols.subsets=rbind(cols.subsets, data.frame(\"ord\"=row_, \"variable\"=col_))\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Figure out the appropriate number of variables through plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted model `regfit.full` contains `C_p`, `BIC` and `AdjR2` of the models at each number of variables.\n",
    "\n",
    "The measurement of `C_p`, `BIC` indicates the badness of the model, whereas the higher `AdjR2` indicates the better performance of the model.\n",
    "\n",
    "Based on this information, figure out the optimum number of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the function giving a scatter plot based on inputs of `C_p`, `BIC` and `AdjR2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subset_summary=function(values, points, name_){\n",
    "    tmp.df=data.frame(X=seq(1, length(values)), Y=values)\n",
    "    tmp.df2=data.frame(X=points, Y=values[points], name=c(\"C_p\", \"BIC\", \"AdjR2\"))\n",
    "    ggplot()+\n",
    "        geom_line(data=tmp.df, aes(x=X, y=Y))+\n",
    "        geom_point(data=tmp.df2, aes(x=X, y=Y, color=name))+\n",
    "        labs(x = \"# of variables\", y = name_)+\n",
    "        scale_color_hue(name = \"Opt points from\")+\n",
    "        theme(axis.title = element_text(size = 8),legend.title = element_text(size = 8),\n",
    "             legend.text = element_text(size = 8))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate and draw plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store cp, bic and adjR^2 into a list respectively\n",
    "regfit.full.summary=summary(regfit.full)\n",
    "mincp = which.min(regfit.full.summary$cp)\n",
    "minbic = which.min(regfit.full.summary$bic)\n",
    "max_adjr2 = which.max(regfit.full.summary$adjr2)\n",
    "opts=c(mincp, minbic, max_adjr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the lists into the function, then obtain the lists of plots\n",
    "plots.subsets.opts=list()\n",
    "plots.subsets.opts[[1]]=plot_subset_summary(regfit.full.summary$cp, opts, \"C_p\")\n",
    "plots.subsets.opts[[2]]=plot_subset_summary(regfit.full.summary$bic, opts, \"BIC\")\n",
    "plots.subsets.opts[[3]]=plot_subset_summary(regfit.full.summary$adjr2, opts, \"AdjR2\")\n",
    "plots.subsets.opts[[4]]=plot_subset_summary(regfit.full.summary$rss, opts, \"RSS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHgCAMAAAC7G6qeAAAAG1BMVEUAAAAAujgzMzNNTU1h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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw the plots\n",
    "options(repr.plot.width=6,repr.plot.height=4)\n",
    "library(gridExtra)\n",
    "do.call(\"grid.arrange\", c(plots.subsets.opts, ncol=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Min BIC is given by 8 of variables\"\n",
      "[1] \"Min CP  is given by 26 of variables\"\n",
      "[1] \"Min AdjR^2 is given by 37 of variables\"\n"
     ]
    }
   ],
   "source": [
    "# Show the number of variables where cp, bic and adjR^2 is optimum\n",
    "print(paste(\"Min BIC is given by\",minbic,\"of variables\"))\n",
    "print(paste(\"Min CP  is given by\",mincp,\"of variables\"))\n",
    "print(paste(\"Min AdjR^2 is given by\",max_adjr2,\"of variables\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "\n",
    "As the output above shows;\n",
    "\n",
    "    1. The minimum BIC is given by 8 variables\n",
    "    2. The minimum C_P is given by 26 variables\n",
    "    3. The minimum Adjusted R^2 is given by 37 variables\n",
    "\n",
    "In terms of the optimum number of variables based on the minimum C_p, it also gives the almost highest adjusted R^2. In addition, it also performs the lower BIC than adjusted R^2. At this point, the minimum C_p would provide a better model than the minimum adjusted R^2.\n",
    "\n",
    "On the other hand, the point given by the minimum BIC is competitive to the minimum C_p. Its BIC score is far lower than the point given by the minimum C_p although other scores are worse than the point given by the minimum C_p.\n",
    "\n",
    "In the later step, those 2 points are compared and determined which is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the summary given by the minimum CP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = fit.glm$formula, family = binomial, data = df.mincp)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.6704  -0.3654  -0.2654  -0.1977   3.0585  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -4.55969    0.57219  -7.969 1.60e-15 ***\n",
       "APERSAUT     0.78862    0.08829   8.932  < 2e-16 ***\n",
       "APLEZIER     1.92380    0.39945   4.816 1.46e-06 ***\n",
       "MOSTYPE8     0.80520    0.19574   4.114 3.89e-05 ***\n",
       "AWAPART      0.41766    0.14329   2.915 0.003559 ** \n",
       "MOPLLAAG    -0.20477    0.05159  -3.969 7.22e-05 ***\n",
       "MRELGE       0.06520    0.03743   1.742 0.081550 .  \n",
       "MOSTYPE12    1.10710    0.31026   3.568 0.000359 ***\n",
       "ABYSTAND     0.48995    0.30746   1.594 0.111041    \n",
       "AFIETS       0.43650    0.19801   2.204 0.027492 *  \n",
       "MOSTYPE3     0.54221    0.24827   2.184 0.028965 *  \n",
       "MBERBOER    -0.16017    0.07963  -2.011 0.044286 *  \n",
       "MGODPR       0.06321    0.03630   1.741 0.081603 .  \n",
       "MOSTYPE23   -0.99418    0.54154  -1.836 0.066383 .  \n",
       "MINK123M    -0.24293    0.11942  -2.034 0.041933 *  \n",
       "MINKGEM      0.08867    0.05435   1.631 0.102786    \n",
       "AWAOREG      0.79345    0.49528   1.602 0.109149    \n",
       "MOPLMIDD    -0.06693    0.04691  -1.427 0.153617    \n",
       "MOSTYPE38    0.56067    0.24830   2.258 0.023944 *  \n",
       "MOSHOOFD8    0.32424    0.15597   2.079 0.037632 *  \n",
       "ABRAND       0.23599    0.12929   1.825 0.067968 .  \n",
       "AWALAND     -0.81717    0.61787  -1.323 0.185981    \n",
       "MGODOV       0.07205    0.05919   1.217 0.223483    \n",
       "AZEILPL      1.85061    1.41889   1.304 0.192144    \n",
       "MOSTYPE6     0.55172    0.34115   1.617 0.105827    \n",
       "MGEMLEEF     0.11908    0.08079   1.474 0.140498    \n",
       "MSKC         0.07934    0.04356   1.822 0.068521 .  \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 2635.4  on 5820  degrees of freedom\n",
       "Residual deviance: 2321.5  on 5794  degrees of freedom\n",
       "AIC: 2375.5\n",
       "\n",
       "Number of Fisher Scoring iterations: 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols.subsets.mincp=c(as.character(cols.subsets[,\"variable\"])[1:mincp], \"CARAVAN\")\n",
    "df.mincp=df.dm[cols.subsets.mincp]\n",
    "fit.glm.mincp = glm(fit.glm$formula, data = df.mincp, family = binomial)\n",
    "summary(fit.glm.mincp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "\n",
    "- A half of variables are not significant if the p-value set to $\\alpha \\lt 0.1$\n",
    "\n",
    "- It does not includes separation and quasi-separation predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the summary given by the minimum BIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = fit.glm$formula, family = binomial, data = df.dm[cols.subsets.minbic])\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-2.7679  -0.3726  -0.2767  -0.2137   3.0069  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept) -4.06051    0.27329 -14.858  < 2e-16 ***\n",
       "APERSAUT     0.77229    0.08655   8.923  < 2e-16 ***\n",
       "APLEZIER     2.05190    0.38801   5.288 1.24e-07 ***\n",
       "MOSTYPE8     0.71530    0.17855   4.006 6.17e-05 ***\n",
       "AWAPART      0.61071    0.11484   5.318 1.05e-07 ***\n",
       "MOPLLAAG    -0.11905    0.02624  -4.536 5.72e-06 ***\n",
       "MRELGE       0.12805    0.03306   3.873 0.000108 ***\n",
       "MOSTYPE12    0.85131    0.28742   2.962 0.003057 ** \n",
       "ABYSTAND     0.57418    0.30316   1.894 0.058222 .  \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 2635.4  on 5820  degrees of freedom\n",
       "Residual deviance: 2381.5  on 5812  degrees of freedom\n",
       "AIC: 2399.5\n",
       "\n",
       "Number of Fisher Scoring iterations: 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols.subsets.minbic=c(as.character(cols.subsets[,\"variable\"])[1:minbic], \"CARAVAN\")\n",
    "fit.glm.minbic = glm(fit.glm$formula, data = df.dm[cols.subsets.minbic], family = binomial)\n",
    "summary(fit.glm.minbic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "- It does not include separation and quasi-separation predictors\n",
    "- Most of the variables are significant if the p-value set to $\\alpha \\lt 0.1$\n",
    "- Comparing with the summary given by the minimum CP;\n",
    "    - AIC score increases from 2375.5 to 2399.5\n",
    "    - Residual deviance increases from 2321.5 to 2381.5\n",
    "    \n",
    "    \n",
    "- The results above indicate a model performance would be slightly lower than the previous one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the impact of each variable on the deviance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A anova: 9 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Df</th><th scope=col>Deviance</th><th scope=col>Resid. Df</th><th scope=col>Resid. Dev</th><th scope=col>Pr(&gt;Chi)</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>NULL</th><td>NA</td><td>        NA</td><td>5820</td><td>2635.417</td><td>          NA</td></tr>\n",
       "\t<tr><th scope=row>APERSAUT</th><td> 1</td><td>105.393959</td><td>5819</td><td>2530.023</td><td>1.001146e-24</td></tr>\n",
       "\t<tr><th scope=row>APLEZIER</th><td> 1</td><td> 25.439477</td><td>5818</td><td>2504.584</td><td>4.564808e-07</td></tr>\n",
       "\t<tr><th scope=row>MOSTYPE8</th><td> 1</td><td> 35.417122</td><td>5817</td><td>2469.167</td><td>2.661371e-09</td></tr>\n",
       "\t<tr><th scope=row>AWAPART</th><td> 1</td><td> 31.509853</td><td>5816</td><td>2437.657</td><td>1.984308e-08</td></tr>\n",
       "\t<tr><th scope=row>MOPLLAAG</th><td> 1</td><td> 26.899121</td><td>5815</td><td>2410.758</td><td>2.143563e-07</td></tr>\n",
       "\t<tr><th scope=row>MRELGE</th><td> 1</td><td> 18.675417</td><td>5814</td><td>2392.082</td><td>1.549676e-05</td></tr>\n",
       "\t<tr><th scope=row>MOSTYPE12</th><td> 1</td><td>  7.317349</td><td>5813</td><td>2384.765</td><td>6.829206e-03</td></tr>\n",
       "\t<tr><th scope=row>ABYSTAND</th><td> 1</td><td>  3.245623</td><td>5812</td><td>2381.519</td><td>7.161446e-02</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A anova: 9 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & Df & Deviance & Resid. Df & Resid. Dev & Pr(>Chi)\\\\\n",
       "  & <int> & <dbl> & <int> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\tNULL & NA &         NA & 5820 & 2635.417 &           NA\\\\\n",
       "\tAPERSAUT &  1 & 105.393959 & 5819 & 2530.023 & 1.001146e-24\\\\\n",
       "\tAPLEZIER &  1 &  25.439477 & 5818 & 2504.584 & 4.564808e-07\\\\\n",
       "\tMOSTYPE8 &  1 &  35.417122 & 5817 & 2469.167 & 2.661371e-09\\\\\n",
       "\tAWAPART &  1 &  31.509853 & 5816 & 2437.657 & 1.984308e-08\\\\\n",
       "\tMOPLLAAG &  1 &  26.899121 & 5815 & 2410.758 & 2.143563e-07\\\\\n",
       "\tMRELGE &  1 &  18.675417 & 5814 & 2392.082 & 1.549676e-05\\\\\n",
       "\tMOSTYPE12 &  1 &   7.317349 & 5813 & 2384.765 & 6.829206e-03\\\\\n",
       "\tABYSTAND &  1 &   3.245623 & 5812 & 2381.519 & 7.161446e-02\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A anova: 9 × 5\n",
       "\n",
       "| <!--/--> | Df &lt;int&gt; | Deviance &lt;dbl&gt; | Resid. Df &lt;int&gt; | Resid. Dev &lt;dbl&gt; | Pr(&gt;Chi) &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| NULL | NA |         NA | 5820 | 2635.417 |           NA |\n",
       "| APERSAUT |  1 | 105.393959 | 5819 | 2530.023 | 1.001146e-24 |\n",
       "| APLEZIER |  1 |  25.439477 | 5818 | 2504.584 | 4.564808e-07 |\n",
       "| MOSTYPE8 |  1 |  35.417122 | 5817 | 2469.167 | 2.661371e-09 |\n",
       "| AWAPART |  1 |  31.509853 | 5816 | 2437.657 | 1.984308e-08 |\n",
       "| MOPLLAAG |  1 |  26.899121 | 5815 | 2410.758 | 2.143563e-07 |\n",
       "| MRELGE |  1 |  18.675417 | 5814 | 2392.082 | 1.549676e-05 |\n",
       "| MOSTYPE12 |  1 |   7.317349 | 5813 | 2384.765 | 6.829206e-03 |\n",
       "| ABYSTAND |  1 |   3.245623 | 5812 | 2381.519 | 7.161446e-02 |\n",
       "\n"
      ],
      "text/plain": [
       "          Df Deviance   Resid. Df Resid. Dev Pr(>Chi)    \n",
       "NULL      NA         NA 5820      2635.417             NA\n",
       "APERSAUT   1 105.393959 5819      2530.023   1.001146e-24\n",
       "APLEZIER   1  25.439477 5818      2504.584   4.564808e-07\n",
       "MOSTYPE8   1  35.417122 5817      2469.167   2.661371e-09\n",
       "AWAPART    1  31.509853 5816      2437.657   1.984308e-08\n",
       "MOPLLAAG   1  26.899121 5815      2410.758   2.143563e-07\n",
       "MRELGE     1  18.675417 5814      2392.082   1.549676e-05\n",
       "MOSTYPE12  1   7.317349 5813      2384.765   6.829206e-03\n",
       "ABYSTAND   1   3.245623 5812      2381.519   7.161446e-02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "anova(fit.glm.minbic, test = \"Chisq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "- Most of the predictors contribute to reducing the deviance.\n",
    "\n",
    "- Only MOSTYPE 8 (Middle class families) increase deviance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion of feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The set of 8 predictors given by the minimum BIC would be better than another set of 26 predictors given by the minimum CP\n",
    "\n",
    "- The reasons for this decision are;\n",
    "    1. The 8 predictors are simpler and significant except one variable\n",
    "    2. In addition, most of them contribute to the deviance reduction\n",
    "    3. AIC score and residual deviance between the 2 sets of predictors are not very different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure the performance by CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, showing how to calculate the performance of a training model.\n",
    "\n",
    "1. Measurement of evaluation model - ticeval2000.txt\n",
    "\n",
    "    As the assessment document given requires, the accuracy based on **`ticeval2000.txt`** is measured by the method below;\n",
    "\n",
    "    Let $\\alpha$ be the 800 customers who are most likely to have a caravan policy,\n",
    "\n",
    "    and let $\\beta$ be the number of customers who were actually a caravan policyholder.\n",
    "\n",
    "    Then, accuracy is $\\frac{\\beta}{\\alpha}=\\frac{\\beta}{800}$.\n",
    "    \n",
    "\n",
    "2. Measurement of training model - ticdata2000.txt\n",
    "\n",
    "    It should adopt the same measurement method with the evaluation model into the training model.\n",
    "\n",
    "    It is confirmed that the percentage of the caravan policyholders is approximately the same between **`ticdata2000.txt`** and **`ticeval2000.txt`**, which is 0.06.\n",
    "\n",
    "    In addition, the number of observations in **`ticeval2000.txt`** is 4000 and 800 candidates are picked up for evaluation.\n",
    "    \n",
    "    The extracting proportion is $\\frac{1}{5}$.\n",
    "    \n",
    "    In this section, k-fold cross validation is adopted and 1 fold is used for evaluation in this case.\n",
    "    \n",
    "    Let $\\alpha'$ be some customers most likely to purchase the policy, and let $\\beta'$ be the number of the actual policyholders in the evaluation in CV.\n",
    "    \n",
    "    Under this situation, $\\alpha'=1fold*\\frac{1}{5}$ and $\\beta'$ is the actual holders among $\\alpha'$.\n",
    "    \n",
    "    Based on this setting, the accuracy of the training model is measured by $\\frac{\\beta'}{\\alpha'}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the function giving the accuracy based on the method above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cv_accuracy=function(preds, tests=list()){\n",
    "    df.acc=data.frame()\n",
    "    for (i in seq(1, length(preds))){\n",
    "        labels = tests[[i]]\n",
    "        pred = preds[[i]]\n",
    "        # number of caravan policyholder in labels\n",
    "        nholders=sum(labels==1)\n",
    "        # number to pick up\n",
    "        denominator=round(length(labels)*0.2)\n",
    "        # calculate the accuracy\n",
    "        df.rank=data.frame(CARAVAN=labels,rank=rank(-pred), prob=pred)\n",
    "        holder.tgt=nrow(df.rank[(df.rank[,\"rank\"]<=denominator) & (df.rank[,\"CARAVAN\"]==1),])\n",
    "        accuracy=round(holder.tgt/denominator,3)\n",
    "        df.acc=rbind(df.acc, data.frame(one_fold=length(labels),\n",
    "                                        whole_holders=nholders,\n",
    "                                        mostlikely=denominator,\n",
    "                                        detected_holders=holder.tgt,\n",
    "                                        accuracy=accuracy))\n",
    "    }\n",
    "    acc=df.acc[,\"accuracy\"]\n",
    "    print(paste(\"Accuracy mean is\",round(mean(acc[acc!=0]), 3)))\n",
    "    print(paste(\"Accuracy variance is\",round(var(acc[acc!=0]), 5)))\n",
    "    df.acc\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Performing 10 fold cross validatoin (subset selection + logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"caret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n=10\n",
    "folds=createFolds(df.subsetbase[,\"CARAVAN\"],k=n)\n",
    "preds.logi=list()\n",
    "labels.logi=list()\n",
    "\n",
    "for (i in seq(1,n)){\n",
    "    # define train and test predictors\n",
    "    train_cols=cols.subsets.minbic\n",
    "    test_cols=setdiff(cols.subsets.minbic, \"CARAVAN\")\n",
    "    # define train and test data frames\n",
    "    train_set=df.subsetbase[-folds[[i]],train_cols]\n",
    "    test_set=df.subsetbase[folds[[i]],test_cols]\n",
    "    labels=df.subsetbase[folds[[i]],\"CARAVAN\"]\n",
    "    # fitting\n",
    "    fit=glm(CARAVAN~., data=train_set, family = binomial)\n",
    "    # store results into lists\n",
    "    pred=predict(fit,newdata=test_set, type = \"response\")   \n",
    "    preds.logi[[i]]=pred\n",
    "    labels.logi[[i]]=labels\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Measure the accuracy of training model (subset selection + logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy mean is 0.161\"\n",
      "[1] \"Accuracy variance is 0.00065\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 10 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>one_fold</th><th scope=col>whole_holders</th><th scope=col>mostlikely</th><th scope=col>detected_holders</th><th scope=col>accuracy</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>582</td><td>32</td><td>116</td><td>21</td><td>0.181</td></tr>\n",
       "\t<tr><td>582</td><td>38</td><td>116</td><td>20</td><td>0.172</td></tr>\n",
       "\t<tr><td>582</td><td>34</td><td>116</td><td>19</td><td>0.164</td></tr>\n",
       "\t<tr><td>582</td><td>47</td><td>116</td><td>25</td><td>0.216</td></tr>\n",
       "\t<tr><td>582</td><td>33</td><td>116</td><td>18</td><td>0.155</td></tr>\n",
       "\t<tr><td>582</td><td>25</td><td>116</td><td>14</td><td>0.121</td></tr>\n",
       "\t<tr><td>582</td><td>28</td><td>116</td><td>18</td><td>0.155</td></tr>\n",
       "\t<tr><td>582</td><td>38</td><td>116</td><td>18</td><td>0.155</td></tr>\n",
       "\t<tr><td>583</td><td>42</td><td>117</td><td>18</td><td>0.154</td></tr>\n",
       "\t<tr><td>582</td><td>31</td><td>116</td><td>16</td><td>0.138</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 10 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       " one\\_fold & whole\\_holders & mostlikely & detected\\_holders & accuracy\\\\\n",
       " <int> & <int> & <dbl> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 582 & 32 & 116 & 21 & 0.181\\\\\n",
       "\t 582 & 38 & 116 & 20 & 0.172\\\\\n",
       "\t 582 & 34 & 116 & 19 & 0.164\\\\\n",
       "\t 582 & 47 & 116 & 25 & 0.216\\\\\n",
       "\t 582 & 33 & 116 & 18 & 0.155\\\\\n",
       "\t 582 & 25 & 116 & 14 & 0.121\\\\\n",
       "\t 582 & 28 & 116 & 18 & 0.155\\\\\n",
       "\t 582 & 38 & 116 & 18 & 0.155\\\\\n",
       "\t 583 & 42 & 117 & 18 & 0.154\\\\\n",
       "\t 582 & 31 & 116 & 16 & 0.138\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 10 × 5\n",
       "\n",
       "| one_fold &lt;int&gt; | whole_holders &lt;int&gt; | mostlikely &lt;dbl&gt; | detected_holders &lt;int&gt; | accuracy &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 582 | 32 | 116 | 21 | 0.181 |\n",
       "| 582 | 38 | 116 | 20 | 0.172 |\n",
       "| 582 | 34 | 116 | 19 | 0.164 |\n",
       "| 582 | 47 | 116 | 25 | 0.216 |\n",
       "| 582 | 33 | 116 | 18 | 0.155 |\n",
       "| 582 | 25 | 116 | 14 | 0.121 |\n",
       "| 582 | 28 | 116 | 18 | 0.155 |\n",
       "| 582 | 38 | 116 | 18 | 0.155 |\n",
       "| 583 | 42 | 117 | 18 | 0.154 |\n",
       "| 582 | 31 | 116 | 16 | 0.138 |\n",
       "\n"
      ],
      "text/plain": [
       "   one_fold whole_holders mostlikely detected_holders accuracy\n",
       "1  582      32            116        21               0.181   \n",
       "2  582      38            116        20               0.172   \n",
       "3  582      34            116        19               0.164   \n",
       "4  582      47            116        25               0.216   \n",
       "5  582      33            116        18               0.155   \n",
       "6  582      25            116        14               0.121   \n",
       "7  582      28            116        18               0.155   \n",
       "8  582      38            116        18               0.155   \n",
       "9  583      42            117        18               0.154   \n",
       "10 582      31            116        16               0.138   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_cv_accuracy(preds.logi, labels.logi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "\n",
    "- Roughly half of the actual caravan policyholders are found by this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure the accuracy of evaluation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, do the prediction by the model including 8 predictors chosen based on BIC.\n",
    "\n",
    "The input data for prediction is `ticeval2000.txt` and the corresponding label data is `tictgts2000.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.eval.initial = read.delim(sep = \"\\t\", file = \"./data/ticeval2000.txt\")\n",
    "cols.eval.initial=c('MOSTYPE','MAANTHUI','MGEMOMV','MGEMLEEF','MOSHOOFD','MGODRK','MGODPR','MGODOV','MGODGE','MRELGE','MRELSA','MRELOV','MFALLEEN','MFGEKIND','MFWEKIND','MOPLHOOG','MOPLMIDD','MOPLLAAG','MBERHOOG','MBERZELF','MBERBOER','MBERMIDD','MBERARBG','MBERARBO','MSKA','MSKB1','MSKB2','MSKC','MSKD','MHHUUR','MHKOOP','MAUT1','MAUT2','MAUT0','MZFONDS','MZPART','MINKM30','MINK3045','MINK4575','MINK7512','MINK123M','MINKGEM','MKOOPKLA','PWAPART','PWABEDR','PWALAND','PPERSAUT','PBESAUT','PMOTSCO','PVRAAUT','PAANHANG','PTRACTOR','PWERKT','PBROM','PLEVEN','PPERSONG','PGEZONG','PWAOREG','PBRAND','PZEILPL','PPLEZIER','PFIETS','PINBOED','PBYSTAND','AWAPART','AWABEDR','AWALAND','APERSAUT','ABESAUT','AMOTSCO','AVRAAUT','AAANHANG','ATRACTOR','AWERKT','ABROM','ALEVEN','APERSONG','AGEZONG','AWAOREG','ABRAND','AZEILPL','APLEZIER','AFIETS','AINBOED','ABYSTAND')\n",
    "names(df.eval.initial)=cols.eval.initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check the correspondings between categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before generating dummied predictors, confirm that the categorical variables in `ticeval2000.txt` have the same values sets with `ticdata2000.txt`.\n",
    "\n",
    "For example, if overlook that the variable `MOSTYPE15` exits in `ticeval2000.txt` but it does not exist in `ticdata2000.txt`, it results in the mismatch of those features and leads to the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check each categorical value set is equal\n",
    "setequal(sort(unique(df[,\"MOSTYPE\"])), sort(unique(df.eval.initial[,\"MOSTYPE\"])))\n",
    "setequal(sort(unique(df[,\"MOSHOOFD\"])), sort(unique(df.eval.initial[,\"MOSHOOFD\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no non-corresponding values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate dummied variables for evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factorise 2 categorical but numeric cols\n",
    "MOSTYPE=as.factor(df.eval.initial$MOSTYPE)\n",
    "MOSHOOFD=as.factor(df.eval.initial$MOSHOOFD)\n",
    "# dummying and store into eval data frame\n",
    "df.eval.dm=cbind(df.eval.initial, dummy.data.frame(data.frame(MOSTYPE, MOSHOOFD)))\n",
    "# drop duplicated cols\n",
    "df.eval.dm=df.eval.dm[, -which (colnames(df.eval.dm) %in% c(\"MOSTYPE\",\"MOSHOOFD\",\"MOSHOOFD10\",\"MOSTYPE41\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter predictors into ones chosen based on the result of subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.eval.minbc=df.eval.dm[,setdiff(cols.subsets.minbic,\"CARAVAN\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction  based on the evaluation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model based on `ticdata2000.txt` is already created as below while performing the subset selection \n",
    "\n",
    "`fit.glm.minbic = glm(fit.glm$formula, data = df.dm[cols.subsets.minbic], family = binomial)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.eval.minbic=predict(fit.glm.minbic, newdata=df.eval.minbc, newtype = \"response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure the accuracy\n",
    "\n",
    "Measure the accuracy based on the idea below.\n",
    "\n",
    "<i>Let $\\alpha$ be the 800 customers who are most likely to have a caravan policy,</i>\n",
    "\n",
    "<i>and let $\\beta$ be the number of customers who were actually a caravan policyholder.</i>\n",
    "\n",
    "<i>Then, accuracy is $\\frac{\\beta}{\\alpha}$.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the function giving the accuracy of a evaluation model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_eval_accuracy=function(pred, labels){\n",
    "    # number of caravan policyholder in labels\n",
    "    nholders=sum(labels==1)\n",
    "    # number to pick up\n",
    "    denominator=round(length(labels)*0.2)\n",
    "    # calculate the accuracy\n",
    "    df.rank=data.frame(CARAVAN=labels,rank=rank(-pred), prob=pred)\n",
    "    holder.tgt=nrow(df.rank[(df.rank[,\"rank\"]<=denominator) & (df.rank[,\"CARAVAN\"]==1),])\n",
    "    denominator=round(length(labels)*0.2)\n",
    "    result=round(holder.tgt/denominator,3)\n",
    "    data.frame(observations=length(labels),\n",
    "               whole_holders=nholders,\n",
    "               mostlikely=denominator,\n",
    "               detected_holders=holder.tgt,\n",
    "               accuracy=result)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "targets = read.delim(sep = \"\\t\", file = \"./data/tictgts2000.txt\")[,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 1 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>observations</th><th scope=col>whole_holders</th><th scope=col>mostlikely</th><th scope=col>detected_holders</th><th scope=col>accuracy</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>3999</td><td>238</td><td>800</td><td>101</td><td>0.126</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       " observations & whole\\_holders & mostlikely & detected\\_holders & accuracy\\\\\n",
       " <int> & <int> & <dbl> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 3999 & 238 & 800 & 101 & 0.126\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 5\n",
       "\n",
       "| observations &lt;int&gt; | whole_holders &lt;int&gt; | mostlikely &lt;dbl&gt; | detected_holders &lt;int&gt; | accuracy &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 3999 | 238 | 800 | 101 | 0.126 |\n",
       "\n"
      ],
      "text/plain": [
       "  observations whole_holders mostlikely detected_holders accuracy\n",
       "1 3999         238           800        101              0.126   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_eval_accuracy(pred.eval.minbic, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "The evaluation model would be overfitting to the training data of `ticdata2000.txt` because the accuracy based on the evaluation data `ticeval2000.txt` shows the lower accuracy than the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary  (subset selection + logistic regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 8 predictors are chosen by subset selection\n",
    "\n",
    "- All of the predictors are significant except MOSTYPE8\n",
    "\n",
    "- Accuracy of evaluation data is 0.126\n",
    "\n",
    "- Mean of accuracies given by cross-validation is 0.164, the variance is 0.00078"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the changing coefficients in accordance with lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fitting the training data `ticdata2000.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(glmnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the fitted data\n",
    "modelmat.lasso=model.matrix(fit.glm$formula, data = df.subsetbase)[,-1] # [,-1] is to removes intercept\n",
    "# fitting\n",
    "fit.lasso=glmnet(x=modelmat.lasso,y=df.subsetbase[,\"CARAVAN\"], alpha=1, family='binomial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot how coefficients of predictors change in accordance with lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8AAAAJYCAMAAACaSn8zAAAAP1BMVEUAAAAAAP8AzQAA//9N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\nnTpsrF/ANwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width=8,repr.plot.height=5)\n",
    "plot(fit.lasso, xvar=\"lambda\",label = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the figures across the top are the number of nonzero coefficient predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count the number of non-zero coefficients where log lambda is -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "15"
      ],
      "text/latex": [
       "15"
      ],
      "text/markdown": [
       "15"
      ],
      "text/plain": [
       "[1] 15"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# count the number of non-zero coefficients where log lambda is -5\n",
    "data.frame(no=attr(coef(fit.lasso, s = exp(-5)),\"i\"), coef=attr(coef(fit.lasso, s = exp(-5)),\"x\")) %>% subset(coef > 0) %>% nrow-1 # minus the intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Findings\n",
    "\n",
    "- Overall, when the lambda increases, the number of predictors decreases\n",
    "\n",
    "- It could be said that penalising does works\n",
    "\n",
    "- For example, the number of non-zero coefficients where $log(\\lambda)=-5$ is 15 predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation to figure out the best hyper parameter lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, figure out the appropriate number of lambda based on indicators which cross-validation gives.\n",
    "\n",
    "In this section, 10 fold cross validation is adopted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fitting with cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 10 fold, which is the default method for cv.glmnet()\n",
    "# 20 fold has been tried but lambda.min was unchanged, so, 10 fold is enough for here\n",
    "cvfit.lasso=cv.glmnet(modelmat.lasso,y=df.subsetbase[,\"CARAVAN\"], alpha=1, family='binomial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the result\n",
    "Check the changing deviance while lambda is increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAHgCAMAAAC7G6qeAAAANlBMVEUAAABNTU1oaGh8fHyM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\nhAas+B9/xy25X4njtQAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width=6,repr.plot.height=4)\n",
    "plot(cvfit.lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show the optimum lambda and the number of vairables correponding to lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.00304447795389617"
      ],
      "text/latex": [
       "0.00304447795389617"
      ],
      "text/markdown": [
       "0.00304447795389617"
      ],
      "text/plain": [
       "[1] 0.003044478"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.0214781900649984"
      ],
      "text/latex": [
       "0.0214781900649984"
      ],
      "text/markdown": [
       "0.0214781900649984"
      ],
      "text/plain": [
       "[1] 0.02147819"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "43"
      ],
      "text/latex": [
       "43"
      ],
      "text/markdown": [
       "43"
      ],
      "text/plain": [
       "[1] 43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4"
      ],
      "text/latex": [
       "4"
      ],
      "text/markdown": [
       "4"
      ],
      "text/plain": [
       "[1] 4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show lambda where the deviance is minimum\n",
    "cvfit.lasso$lambda.min\n",
    "cvfit.lasso$lambda.1se\n",
    "# count the number of non-zero coefficients where the lambda is min, 1se\n",
    "data.frame(no=attr(coef(fit.lasso, s = cvfit.lasso$lambda.min),\"i\"), coef=attr(coef(fit.lasso, s = cvfit.lasso$lambda.min),\"x\")) %>% subset(abs(coef) > 0) %>% nrow-1 # minus the intercept\n",
    "data.frame(no=attr(coef(fit.lasso, s = cvfit.lasso$lambda.1se),\"i\"), coef=attr(coef(fit.lasso, s = cvfit.lasso$lambda.1se),\"x\")) %>% subset(abs(coef) > 0) %>% nrow-1 # minus the intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Findings 1\n",
    "\n",
    "- There is a minimum deviance point where $\\lambda \\approx0.0025$.\n",
    "\n",
    "- The number of predictors at the lambda is 47.\n",
    "\n",
    "##### Findings 2\n",
    "\n",
    "- There is the 1se deviance point from the minimum where $\\lambda \\approx0.0123$.\n",
    "\n",
    "- The number of predictors at the lambda is 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation to measure the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both $\\lambda$ giving the minimum deviance and the 1se-deviance could be the candidates of a hyperparameter which produce the best accuracy.\n",
    "\n",
    "Hence, try both parameters in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the function performing the k-fold cross validation and return the results of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"caret\")\n",
    "cv_kfold_lasso=function(kfold, lambda){\n",
    "    folds=createFolds(df.subsetbase[,\"CARAVAN\"],k=kfold)\n",
    "    preds.lasso=list()\n",
    "    labels.lasso=list()\n",
    "    fits.lasso=list()\n",
    "\n",
    "    for (i in seq(1,kfold)){\n",
    "        # define train and test predictors\n",
    "        train_cols=setdiff(cols.subsetbase, \"CARAVAN\")\n",
    "        # define train and test data frames\n",
    "        train_data  =data.matrix(df.subsetbase[-folds[[i]],train_cols])\n",
    "        train_labels=df.subsetbase[-folds[[i]],\"CARAVAN\"]\n",
    "        test_data   =data.matrix(df.subsetbase[ folds[[i]],train_cols])\n",
    "        test_labels =df.subsetbase[ folds[[i]],\"CARAVAN\"]\n",
    "        # fitting\n",
    "        fit=glmnet(x=train_data, y=train_labels, alpha=1, family='binomial', lambda=lambda)\n",
    "        # store results into lists\n",
    "        pred=predict(fit, newx=test_data)\n",
    "        preds.lasso[[i]]=as.numeric(pred)\n",
    "        labels.lasso[[i]]=test_labels\n",
    "        fits.lasso[[i]]=fit\n",
    "    }\n",
    "    list(preds.lasso, labels.lasso, fits.lasso)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CV by `lambda.min`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_min=cv_kfold_lasso(kfold = 10, lambda=cvfit.lasso$lambda.min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Issue when executing `cv_kfold_lasso` with `lambda.min`\n",
    "\n",
    "This execution sometimes get the warning message below;\n",
    "\n",
    "<p style=\"background-color: #fdd;\">Convergence for 1th lambda value not reached after maxit=100000 iterations; solutions for larger \n",
    " lambdas returned </p>\n",
    "\n",
    "It occurs when `glmnet()` is executed because lambda.min is too low to convergent.\n",
    "\n",
    "There are 2 solutions to this issue;\n",
    "\n",
    "1. Use a larger lambda as the message suggests, such as lambda.1se\n",
    "\n",
    "2. Use a model fitted by cv.glmnet() according to [a forum](https://stats.stackexchange.com/questions/101101/convergence-for-1st-lambda-value-not-reached-error-using-glmnet-package-and-sp)\n",
    "\n",
    "However, the 2nd solution is not appropriate since a model fitted by cv.glmnet() contains a whole training data. For cross-validation, data for testing should not be involved in the model.\n",
    "\n",
    "Hence, **the lambda of 1se is adopted in the later section**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicting and measure the accuracy based on `lambda.1se`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy mean is 0.114\"\n",
      "[1] \"Accuracy variance is 0.00151\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 10 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>one_fold</th><th scope=col>whole_holders</th><th scope=col>mostlikely</th><th scope=col>detected_holders</th><th scope=col>accuracy</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>582</td><td>30</td><td>116</td><td>17</td><td>0.147</td></tr>\n",
       "\t<tr><td>583</td><td>35</td><td>117</td><td>19</td><td>0.162</td></tr>\n",
       "\t<tr><td>582</td><td>38</td><td>116</td><td>14</td><td>0.121</td></tr>\n",
       "\t<tr><td>582</td><td>41</td><td>116</td><td>17</td><td>0.147</td></tr>\n",
       "\t<tr><td>582</td><td>35</td><td>116</td><td> 6</td><td>0.052</td></tr>\n",
       "\t<tr><td>582</td><td>32</td><td>116</td><td>13</td><td>0.112</td></tr>\n",
       "\t<tr><td>582</td><td>38</td><td>116</td><td>14</td><td>0.121</td></tr>\n",
       "\t<tr><td>582</td><td>39</td><td>116</td><td> 6</td><td>0.052</td></tr>\n",
       "\t<tr><td>582</td><td>30</td><td>116</td><td>10</td><td>0.086</td></tr>\n",
       "\t<tr><td>582</td><td>30</td><td>116</td><td>16</td><td>0.138</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 10 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       " one\\_fold & whole\\_holders & mostlikely & detected\\_holders & accuracy\\\\\n",
       " <int> & <int> & <dbl> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 582 & 30 & 116 & 17 & 0.147\\\\\n",
       "\t 583 & 35 & 117 & 19 & 0.162\\\\\n",
       "\t 582 & 38 & 116 & 14 & 0.121\\\\\n",
       "\t 582 & 41 & 116 & 17 & 0.147\\\\\n",
       "\t 582 & 35 & 116 &  6 & 0.052\\\\\n",
       "\t 582 & 32 & 116 & 13 & 0.112\\\\\n",
       "\t 582 & 38 & 116 & 14 & 0.121\\\\\n",
       "\t 582 & 39 & 116 &  6 & 0.052\\\\\n",
       "\t 582 & 30 & 116 & 10 & 0.086\\\\\n",
       "\t 582 & 30 & 116 & 16 & 0.138\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 10 × 5\n",
       "\n",
       "| one_fold &lt;int&gt; | whole_holders &lt;int&gt; | mostlikely &lt;dbl&gt; | detected_holders &lt;int&gt; | accuracy &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 582 | 30 | 116 | 17 | 0.147 |\n",
       "| 583 | 35 | 117 | 19 | 0.162 |\n",
       "| 582 | 38 | 116 | 14 | 0.121 |\n",
       "| 582 | 41 | 116 | 17 | 0.147 |\n",
       "| 582 | 35 | 116 |  6 | 0.052 |\n",
       "| 582 | 32 | 116 | 13 | 0.112 |\n",
       "| 582 | 38 | 116 | 14 | 0.121 |\n",
       "| 582 | 39 | 116 |  6 | 0.052 |\n",
       "| 582 | 30 | 116 | 10 | 0.086 |\n",
       "| 582 | 30 | 116 | 16 | 0.138 |\n",
       "\n"
      ],
      "text/plain": [
       "   one_fold whole_holders mostlikely detected_holders accuracy\n",
       "1  582      30            116        17               0.147   \n",
       "2  583      35            117        19               0.162   \n",
       "3  582      38            116        14               0.121   \n",
       "4  582      41            116        17               0.147   \n",
       "5  582      35            116         6               0.052   \n",
       "6  582      32            116        13               0.112   \n",
       "7  582      38            116        14               0.121   \n",
       "8  582      39            116         6               0.052   \n",
       "9  582      30            116        10               0.086   \n",
       "10 582      30            116        16               0.138   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_1se=cv_kfold_lasso(kfold = 10, lambda=cvfit.lasso$lambda.1se)\n",
    "get_cv_accuracy(preds = results_1se[[1]], tests = results_1se[[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm the coefficients chosen by `lambda.1se`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By executing `coef(cvfit.lasso, s = \"lambda.1se\")`, the predictor list and their coefficients are extracted as below;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| variable    | description                        | coefficient |\n",
    "|-------------|------------------------------------|-------------|\n",
    "| (Intercept) | -                                  | -3.4716     |\n",
    "| MRELGE      | Married                            | 0.0052      |\n",
    "| MOPLHOOG    | High level education               | 0.0060      |\n",
    "| MOPLLAAG    | Lower level education              | -0.0278     |\n",
    "| MAUT1       | 1 car                              | 0.0024      |\n",
    "| MINKGEM     | Average income                     | 0.0372      |\n",
    "| MKOOPKLA    | Purchasing power class             | 0.0371      |\n",
    "| AWAPART     | # of private third party insurance | 0.2212      |\n",
    "| APERSAUT    | # of car policies                  | 0.5171      |\n",
    "| APLEZIER    | # of boat policies                 | 1.1687      |\n",
    "| MOSTYPE8    | Middle class families              | 0.3339      |\n",
    "\n",
    "##### Findings\n",
    "\n",
    "- The number of boat policies is far larger than other features\n",
    "- All of the predictors have positive coefficients except lower level education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure the accuracy of evaluation data  (Lasso Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, do the prediction based on the evaluation data by the Lasso model.\n",
    "\n",
    "The input data for prediction is `ticeval2000.txt` and the corresponding label data is `tictgts2000.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data frame based on `ticeval2000.txt` and then filter predictors into the same ones used in CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=setdiff(cols.subsetbase, \"CARAVAN\")\n",
    "xmat.eval.lasso=data.matrix(df.eval.dm[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction by lambda.1se\n",
    "The Model based on the whole data of `ticdata2000.txt` is already created as below while doing cross-validation.\n",
    "\n",
    "`cvfit.lasso=cv.glmnet()`\n",
    "\n",
    "Doing prediction by this model and the evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.eval.lasso.1se=predict(cvfit.lasso, newx=xmat.eval.lasso, newtype = \"response\", s = \"lambda.1se\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Measure the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 1 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>observations</th><th scope=col>whole_holders</th><th scope=col>mostlikely</th><th scope=col>detected_holders</th><th scope=col>accuracy</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>3999</td><td>238</td><td>800</td><td>91</td><td>0.114</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       " observations & whole\\_holders & mostlikely & detected\\_holders & accuracy\\\\\n",
       " <int> & <int> & <dbl> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 3999 & 238 & 800 & 91 & 0.114\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 5\n",
       "\n",
       "| observations &lt;int&gt; | whole_holders &lt;int&gt; | mostlikely &lt;dbl&gt; | detected_holders &lt;int&gt; | accuracy &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 3999 | 238 | 800 | 91 | 0.114 |\n",
       "\n"
      ],
      "text/plain": [
       "  observations whole_holders mostlikely detected_holders accuracy\n",
       "1 3999         238           800        91               0.114   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_eval_accuracy(pred.eval.lasso.1se, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary where lambda is `lambda.1se`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The number of predictors is 10\n",
    "\n",
    "- The mean of accuracies of CV is 0.157 and its variance is 0.00091\n",
    "\n",
    "- The accuracy based on the evaluation data is 0.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third model\n",
    "# Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the findings in the previous exploration, the predictors below are used for prediction.\n",
    "\n",
    "1. MOPLLAAG - Lower level education\n",
    "2. MBERARBG - Skilled labourers\n",
    "3. MBERHOOG - High status\n",
    "4. MSKC - Social class C\n",
    "5. MINK4575 - Income 45-75.000\n",
    "6. MINKGEM - Average income\n",
    "7. MKOOPKLA - Purchasing power class\n",
    "8. MAUT1 - 1 car\n",
    "9. ABRAND - Number of fire policies\n",
    "10. AWAPART - Number of private third party insurance\n",
    "11. APERSAUT - Number of car policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform cross-validation to measure the accuracy of the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CV with 10 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lda=df.dm[c(cols.lda, \"CARAVAN\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"caret\")\n",
    "library(\"MASS\")\n",
    "kfold=10\n",
    "folds=createFolds(df.lda[,\"CARAVAN\"],k=kfold)\n",
    "preds.lda=list()\n",
    "labels.lda=list()\n",
    "\n",
    "for (i in seq(1,kfold)){\n",
    "    # define train and test predictors\n",
    "    train_cols=setdiff(cols.lda, \"CARAVAN\")\n",
    "    # define train and test data frames\n",
    "    train_data  =df.lda[-folds[[i]],train_cols]\n",
    "    train_labels=df.lda[-folds[[i]],\"CARAVAN\"]\n",
    "    test_data   =df.lda[ folds[[i]],train_cols]\n",
    "    test_labels =df.lda[ folds[[i]],\"CARAVAN\"]\n",
    "    # fitting\n",
    "    fit=lda(x=train_data, grouping=train_labels)\n",
    "    # store results into lists\n",
    "    pred=predict(object=fit, newdata=test_data)\n",
    "    preds.lda[[i]]=pred$x[,\"LD1\"]\n",
    "    labels.lda[[i]]=test_labels\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Measure the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Accuracy mean is 0.146\"\n",
      "[1] \"Accuracy variance is 0.00118\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 10 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>one_fold</th><th scope=col>whole_holders</th><th scope=col>mostlikely</th><th scope=col>detected_holders</th><th scope=col>accuracy</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>583</td><td>39</td><td>117</td><td>12</td><td>0.103</td></tr>\n",
       "\t<tr><td>582</td><td>19</td><td>116</td><td>12</td><td>0.103</td></tr>\n",
       "\t<tr><td>582</td><td>37</td><td>116</td><td>20</td><td>0.172</td></tr>\n",
       "\t<tr><td>582</td><td>28</td><td>116</td><td>16</td><td>0.138</td></tr>\n",
       "\t<tr><td>582</td><td>35</td><td>116</td><td>19</td><td>0.164</td></tr>\n",
       "\t<tr><td>582</td><td>46</td><td>116</td><td>23</td><td>0.198</td></tr>\n",
       "\t<tr><td>582</td><td>41</td><td>116</td><td>22</td><td>0.190</td></tr>\n",
       "\t<tr><td>582</td><td>35</td><td>116</td><td>13</td><td>0.112</td></tr>\n",
       "\t<tr><td>582</td><td>36</td><td>116</td><td>16</td><td>0.138</td></tr>\n",
       "\t<tr><td>582</td><td>32</td><td>116</td><td>17</td><td>0.147</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 10 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       " one\\_fold & whole\\_holders & mostlikely & detected\\_holders & accuracy\\\\\n",
       " <int> & <int> & <dbl> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 583 & 39 & 117 & 12 & 0.103\\\\\n",
       "\t 582 & 19 & 116 & 12 & 0.103\\\\\n",
       "\t 582 & 37 & 116 & 20 & 0.172\\\\\n",
       "\t 582 & 28 & 116 & 16 & 0.138\\\\\n",
       "\t 582 & 35 & 116 & 19 & 0.164\\\\\n",
       "\t 582 & 46 & 116 & 23 & 0.198\\\\\n",
       "\t 582 & 41 & 116 & 22 & 0.190\\\\\n",
       "\t 582 & 35 & 116 & 13 & 0.112\\\\\n",
       "\t 582 & 36 & 116 & 16 & 0.138\\\\\n",
       "\t 582 & 32 & 116 & 17 & 0.147\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 10 × 5\n",
       "\n",
       "| one_fold &lt;int&gt; | whole_holders &lt;int&gt; | mostlikely &lt;dbl&gt; | detected_holders &lt;int&gt; | accuracy &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 583 | 39 | 117 | 12 | 0.103 |\n",
       "| 582 | 19 | 116 | 12 | 0.103 |\n",
       "| 582 | 37 | 116 | 20 | 0.172 |\n",
       "| 582 | 28 | 116 | 16 | 0.138 |\n",
       "| 582 | 35 | 116 | 19 | 0.164 |\n",
       "| 582 | 46 | 116 | 23 | 0.198 |\n",
       "| 582 | 41 | 116 | 22 | 0.190 |\n",
       "| 582 | 35 | 116 | 13 | 0.112 |\n",
       "| 582 | 36 | 116 | 16 | 0.138 |\n",
       "| 582 | 32 | 116 | 17 | 0.147 |\n",
       "\n"
      ],
      "text/plain": [
       "   one_fold whole_holders mostlikely detected_holders accuracy\n",
       "1  583      39            117        12               0.103   \n",
       "2  582      19            116        12               0.103   \n",
       "3  582      37            116        20               0.172   \n",
       "4  582      28            116        16               0.138   \n",
       "5  582      35            116        19               0.164   \n",
       "6  582      46            116        23               0.198   \n",
       "7  582      41            116        22               0.190   \n",
       "8  582      35            116        13               0.112   \n",
       "9  582      36            116        16               0.138   \n",
       "10 582      32            116        17               0.147   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_cv_accuracy(preds = preds.lda, tests = labels.lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure the accuracy of evaluation data  (Linear Discriminant Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, do the prediction based on the evaluation data by LDA.\n",
    "\n",
    "The input data for prediction is `ticeval2000.txt` and the corresponding label data is `tictgts2000.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fitting\n",
    "Generate the model based on the whole data of `ticdata2000.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.lda=lda(x=df.lda[cols.lda], grouping=df.dm[,\"CARAVAN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Have a look the fittied model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Call:\n",
       "lda(df.lda[cols.lda], grouping = df.dm[, \"CARAVAN\"])\n",
       "\n",
       "Prior probabilities of groups:\n",
       "         0          1 \n",
       "0.94021646 0.05978354 \n",
       "\n",
       "Group means:\n",
       "  MOPLLAAG MBERARBG     MSKC MINK4575  MINKGEM MKOOPKLA    MAUT1 APERSAUT\n",
       "0 4.624520 2.237895 3.778915 2.702905 3.754431 4.188014 6.012607 0.540106\n",
       "1 3.747126 1.928161 3.433908 3.172414 4.255747 5.000000 6.471264 0.908046\n",
       "  MBERHOOG    ABRAND   AWAPART\n",
       "0 1.865704 0.5613009 0.3919240\n",
       "1 2.359195 0.7068966 0.5775862\n",
       "\n",
       "Coefficients of linear discriminants:\n",
       "                 LD1\n",
       "MOPLLAAG -0.13008332\n",
       "MBERARBG -0.03454220\n",
       "MSKC      0.10124422\n",
       "MINK4575 -0.02481472\n",
       "MINKGEM   0.16567077\n",
       "MKOOPKLA  0.11020646\n",
       "MAUT1     0.10699209\n",
       "APERSAUT  1.10232280\n",
       "MBERHOOG  0.04085439\n",
       "ABRAND    0.24769507\n",
       "AWAPART   0.56238007"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit.lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data frame based on `ticeval2000.txt` and then filter predictors into the same ones used in CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.eval.lda=df.eval.dm[cols.lda]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.eval.lda=predict(object=fit.lda, newdata=df.eval.lda)$x[,\"LD1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Measure the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 1 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>observations</th><th scope=col>whole_holders</th><th scope=col>mostlikely</th><th scope=col>detected_holders</th><th scope=col>accuracy</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>3999</td><td>238</td><td>800</td><td>108</td><td>0.135</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       " observations & whole\\_holders & mostlikely & detected\\_holders & accuracy\\\\\n",
       " <int> & <int> & <dbl> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 3999 & 238 & 800 & 108 & 0.135\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 5\n",
       "\n",
       "| observations &lt;int&gt; | whole_holders &lt;int&gt; | mostlikely &lt;dbl&gt; | detected_holders &lt;int&gt; | accuracy &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 3999 | 238 | 800 | 108 | 0.135 |\n",
       "\n"
      ],
      "text/plain": [
       "  observations whole_holders mostlikely detected_holders accuracy\n",
       "1 3999         238           800        108              0.135   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_eval_accuracy(pred.eval.lda, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary  (Linear Discriminant Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The number of predictors is 11\n",
    "\n",
    "- The mean of accuracies of CV is 0.149 and its variance is 0.00161\n",
    "\n",
    "- The accuracy based on the evaluation data is 0.135"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary of accuracies is below.\n",
    "\n",
    "| Indicator                     | Logistic Regression & Subset Selection | Lasso Logistic Regression | Linear Descriminant Analysis |\n",
    "|-------------------------------|----------------------------------------|---------------------------|------------------------------|\n",
    "| Mean Accuracy in CV           | 0.164                                  | 0.157                     | 0.149                        |\n",
    "| Variance of Accuracy in CV    | 0.00078                                | 0.00091                   | 0.00161                      |\n",
    "| Accuracy with Evaluation Data | 0.126                                  | 0.13                      | 0.135                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model of Logistic Regression with Subset Selection performs the best accuracy in the cross-validation, whereas the actual accuracy with the evaluation data falls into the lowest accuracy. It indicates that the fitted model would be more overfitting than other models.\n",
    "\n",
    "The performance of Lasso Logistic Regression model is situated in the middle between the other 2 models.\n",
    "\n",
    "The model of LDA performs the smallest accuracy gap between CV and the prediction based on the evaluation data. In addition, it achieves the best accuracy with the evaluation data.\n",
    "\n",
    "In conclusion, in terms of accuracy and its stability, LDA is the best model.\n",
    "\n",
    "In terms of the assumptions which the models have, LDA assuming that variables normally and separately distribute shows a better performance than Logistic Regressions which assume that predictors are correlated with a response variable. At this point, it would be insisted that the properties of features which LDA expects are slightly more directly connecting to the prediction of the actual policyholders than other properties of features which Logistic Regression assume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection and their coeffients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, comparing the features which each model selects and their coefficients. The summarised information is shown in the table below.\n",
    "\n",
    "| Data Source       | Variables   | Description                             | Rank of Correlation Ratio | Subset Selection | Lasso  | LDA    |\n",
    "|-------------------|-------------|-----------------------------------------|---------------------------|------------------|--------|--------|\n",
    "| -                 | (Intercept) | -                                       | -                         | -4.061           | -3.472 | -      |\n",
    "| PRODUCT OWNERSHIP | AWAPART     | # of private third party insurance      | 6                         | 0.611            | 0.221  | 0.562  |\n",
    "| PRODUCT OWNERSHIP | ABRAND      | # of fire policies                      | 18                        | -                | -      | 0.248  |\n",
    "| PRODUCT OWNERSHIP | ABYSTAND    | # of social security insurance policies | 13                        | 0.574            | -      | -      |\n",
    "| PRODUCT OWNERSHIP | APERSAUT    | # of car policies                       | 1                         | 0.772            | 0.517  | 1.102  |\n",
    "| PRODUCT OWNERSHIP | APLEZIER    | # of boat policies                      | 2                         | 2.052            | 1.169  | -      |\n",
    "| SOCIO DEMOGRAPHIC | MOSTYPE8    | Middle class families                   | -                         | 0.715            | 0.334  | -      |\n",
    "| SOCIO DEMOGRAPHIC | MOSTYPE12   | Affluent young families                 | -                         | 0.851            | -      | -      |\n",
    "| SOCIO DEMOGRAPHIC | MRELGE      | Married                                 | 11                        | 0.128            | 0.005  | -0.035 |\n",
    "| SOCIO DEMOGRAPHIC | MAUT1       | 1 car                                   | 12                        | -                | 0.002  | 0.107  |\n",
    "| SOCIO DEMOGRAPHIC | MBERARBG    | Skilled labourers                       | 28                        | -                | -      | -      |\n",
    "| SOCIO DEMOGRAPHIC | MOPLLAAG    | Lower level education                   | 4                         | -0.119           | -0.028 | -0.130 |\n",
    "| SOCIO DEMOGRAPHIC | MOPLHOOG    | High level education                    | 7                         | -                | 0.006  | -      |\n",
    "| SOCIO DEMOGRAPHIC | MBERHOOG    | High status                             | 14                        | -                | -      | 0.041  |\n",
    "| SOCIO DEMOGRAPHIC | MSKC        | Social class C                          | 29                        | -                | -      | 0.101  |\n",
    "| SOCIO DEMOGRAPHIC | MINK4575    | Income 45-75.000                        | 20                        | -                | -      | -0.025 |\n",
    "| SOCIO DEMOGRAPHIC | MINKGEM     | Average income                          | 5                         | -                | 0.037  | 0.166  |\n",
    "| SOCIO DEMOGRAPHIC | MKOOPKLA    | Purchasing power class                  | 3                         | -                | 0.037  | 0.110  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the subset selection chooses the same number of features from product ownership and socio-demographic respectively, whereas Lasso and LDA more choose their features from socio-demographic.\n",
    "\n",
    "In terms of similarity of feature selection, the subset selection is more close to Lasso than LDA. It shares 75% of features with Lasso, whereas 50% with LDA. On the other hand, Lasso is situated in the middle between the subset selection and LDA. It shares 60% of its features with the subset selection, likely, it shares 70% of its features with LDA.\n",
    "\n",
    "When it comes to the taste of the whole selected features, most of them directly or indirectly indicate a factor of a wealth of customers, such as social status, income, purchasing power, education level, the number of boat policies.\n",
    "\n",
    "In terms of relationship between the correlation ratio and the feature selection, subset selection and Lasso select mainly from highly correlated variables to CARAVAN, yet LDA selects relatively less correlated variables compared to other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages and Disadvantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of the prediction task, LDA shows the best performance. However, the gap in accuracy is not very large. Namely, Logistic Regression based on the subset selection demonstrates 0.126 accuracies, whereas LDA makes 0.135 accuracies. It corresponds to 101 and 108 detected actual caravan policyholder respectively.\n",
    "\n",
    "When it comes to the description task, Logistic Regression with the subset selection has big advantages comparing to other models. Firstly, it has been figured out that most of the selected features are significant. Secondly, unlike LDA, the figure of coefficients directly denote the amount of contribution to the probability that a customer is an actual caravan policyholder.\n",
    "\n",
    "In conclusion, Logistic Regression with the subset selection is the most appropriate model for the description task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictors having a significant impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the previous paragraph mentions, this task is performed based on the model of Logistic Regression with the subset selection.\n",
    "\n",
    "The selected features and their coefficients are below;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Data Source       | Variables   | Description                             | Coefficient |\n",
    "|-------------------|-------------|-----------------------------------------|------------------|\n",
    "| -                 | (Intercept) | -                                       | -4.061           |\n",
    "| PRODUCT OWNERSHIP | AWAPART     | # of private third party insurance      | 0.611            |\n",
    "| PRODUCT OWNERSHIP | ABYSTAND    | # of social security insurance policies | 0.574            |\n",
    "| PRODUCT OWNERSHIP | APERSAUT    | # of car policies                       | 0.772            |\n",
    "| PRODUCT OWNERSHIP | APLEZIER    | # of boat policies                      | 2.052            |\n",
    "| SOCIO DEMOGRAPHIC | MOSTYPE8    | Middle class families                   | 0.715            |\n",
    "| SOCIO DEMOGRAPHIC | MOSTYPE12   | Affluent young families                 | 0.851            |\n",
    "| SOCIO DEMOGRAPHIC | MRELGE      | Married                                 | 0.128            |\n",
    "| SOCIO DEMOGRAPHIC | MOPLLAAG    | Lower level education                   | -0.119           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on those selected features, the formula to calculate the probability that a customer purchases the caravan policy is denoted as below;\n",
    "\n",
    "$Pr(Caravan = Buy)=(1+\\exp^{-(intercept*0.611*awapart+0.574*abystand+0.772*apersaut+2.052*aplezier+0.715*mostype8+0.851*mostype12+0.128*mrelge-0.119*mopllaag)})^{-1}$\n",
    "\n",
    "A simple interpretation of this formula is that the features having positive coefficients have a positive impact on purchasing the caravan policy. In addition, the size of the coefficient corresponds to the magnitude of the impact. \n",
    "\n",
    "From those views, `the number of boat policies` has the biggest impact on the customer's behaviour. However, the number of customers who actually have that policy also should be considered. Otherwise, fewer customers will be approached by the marketing department. The histograms showing the frequency of the number of policies are below;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAADwCAMAAAAeuqOxAAAAOVBMVEUAAAAzMzNNTU1ZWVlo\naGh8fHyMjIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnh4eHp6enr6+vw8PD///8Yrk7HAAAACXBI\nWXMAABJ0AAASdAHeZh94AAAQiElEQVR4nO2d64KqMBKEWdbb3HT1/R92AUWS0Akdu4FOTvWP\ncaQC+VKWGAS1eaBQFVWzNwAKpVkINKqqQqBRVRUCjaqqEGhUVYVAo6oqBBpVVSHQqKpKGuj/\nPWu8XbwnkMRjpTtKsueIVFsxc8AOn+m2U+cINAKtzcy35yMRgQ5YEei0pMWKQC9IQlIEmilp\nsVoNdNsVdQujEegkq9FAt68/4S2MRqDTrAj0glS20Trs8JluO3XOm0Mj0AwRgfZZiwv0f/oa\n5P9OJXZjxRrG77D+d0ujldmX4HYP9F4+swLdPtJ7aBgdaytmjrFLzUxI6qwINC2VbbQyu9TM\nhKTOai7QrfsHgc5pK2aOsUvNTEjqrNYC3U5/EejMtmLmGLvUzISkzmos0K1zg0BnthUzx9il\nZiYkdVZbgW7b16nBxJlCg0a3E7wNo4UVskvNTEg6wK7POlvklcq1HPaMbp15UpQVgSYldVZb\ne+hMeKmbCSmDqn0g0B9L6qwINC1lcQVT/f2NrtRnDisCTUtZXO/p/jPU5FlN06c1g7LqM4cV\ngaalLK7W/7O/0ZX6zGFFoGkpi6sl/gtZEWhSUmdFoGkpiwuB/lhSZ0WgaSmLq7Ypx1AOuu6G\ndWtXn6sPdOIkUEmBDtmlZiYkdVYEmpayuKYzhUaMrtRnDisCTUtCUgSaKamzItC0JCRFoJmS\nOisCTUtCUgSaKamzFhXooRx2jc2tVbsarcy+BIdAK8FL3UxIQlIEmimpsyLQtCQkRaCZkjor\nAk1LQlIEmimpsyLQtCQkRaCZkjorAk1LQlIEmimpsyLQtCQkRaCZkjorAk1LQlIEmimpsyLQ\ntCQkRaCZkjorAk1LQlIEmimpsyLQtCQkRaCZkjorAk1LQlIEmimpsyLQtCQkRaCZkjorAk1L\nQlIEmillcZn7IAUCjUALmFtzn938lwI9lGu0zhY3KZs+t/Y+jMz+wvNH+C2klo2mK2TFHpqU\nsrhKDLT/TZ74fuictmLmGLvUzISUxRUEev+vXON84TkCzRIRaAs+5/3GyjK81M2ElGU0VSGr\nrUAzfoLaoM8FB3qcQr+X4HcKNQPN+cVeBDrWdgLCr2Ah0B8zP0oO9PhfIUZTFbKaCnTobyE+\nI9CfS1lGUxWyFhJo01O7Is8UYsrBEuWBdo9R4HNO26nzrED7B4UwGoG253PemUL3FkZrBxqv\nhCxRHugceKmbCUlIaj7QzvkrBDqz7dQ5Am0l0MGZWAQ6p+3UOQJtJNCF/gS1OZ8RaCOBzmSX\nmpmQ1FkRaFoSkiLQTEmdFYGmJSEpAs2U1FkRaFoSkiLQTEmdFYGmJSEpAs2U1FkRaFoSkiLQ\nTEmdFYGmpSwucxfNVOozhxWBpqUcLHsfr6/TZxYrAk1LGVQGP15fpc881j0D3bzuu6/U1o0m\nmY0HuhqfOay7BbptnGIaPZTDnrOaRsWYzX283mX7wOcwJNLUJiQxc8i6W6C/HebvQoyOMVve\nQ9fkM4fVwpSDXSG81M2EFEMgmS0HuiafOaw4KKSlLC7jga7GZw7rroG+jJOlgoymmK0Huhaf\nOax7BvpS2sFKjNl4oKvxmcO6Z6Bb9lGKHaNJZuNnCqvxmcOKg0JaiiGUcbDyD/k8lOtz5lhF\nFUCemnve+gaMZjOHrDsGGj5vtIe+tcdbaUazmUPWHQMNnzebcpR3sFLGGSz4jEBHoUs0Gj7v\nEujsCuGlbiYkIampQH9WDrruhnVrV58R6DICHbJLzUxI6qyYctBSDKGMl0L4jEBHoUs0Gj7v\nOOW4Hb/cu0V8+2jAbM7oD5nhM6vt1Dn9bLs3DrX/+TyzXyLoMdsz+kNm+MxqO3UeeflwXlaC\nz+eZDfTyqdmQdf9Af37aXmpmQirbZxrup4l+Ps9soH1mc0Z/yAyfWW2nzmMHhRdnYSTQVn7M\nhmSmalejP2SOsS/BrRDoMnymA916zMb30CSzOaM/ZIbPrLYOJcNM44FmV8i6/5Tjc3apmQlJ\nnRWBpqWyjVZml5qZkNRZdw30/XJomsPFu/LVeqApZnNGf8gMn1ltp85n10O/Jkrula/GA00y\nR8s1mtN+ncpjfpTlc8i6Z6DPTX8R9+3YnJ2Fxs8UkszmjP6QGT6z2k6dRz5TWNIb/mzmkNXA\nZwrh8zIUAm3SaPhsZ8ph3OgyXgrh8y6BxsHKNoGGzxsFGm8nbRNo+LxVoHMrhJe6mZCEpLYC\nLWWXmpmQ1FkRaFoSkiLQTEmddddAn4YFzaGguR2bOWTdM9B1+dx6JydC1p2/fXRYWtLRN5s5\nZN3320dr8tm/Qjpk3ffbR//6m2tJ74+ymUPWXb99tCqf7QYab/hvE+i6fA4+whKy7hnoU3O+\n9+/PNMdyjGYzh6y7fvsowWz8mpm4z9MUev9fG4udWLky1zdgNJs5ZLVwYsVhtv7p+rjPln4p\nIXJiJe+7Xnd6Mo7FZd7V6EVm+5+uT/tsNNC5FcJL3UxIQlJbgabKeqAZ9Pv7jECbD7SVT9fH\ny/KUI7dC+CU6BDpexe6hWw8VgWZKQlIEmil94KyhXxtDoBFoCbM5n+sOtKFrDDi07h8EOqft\n1HnlgU6yItCk9IHPfoWsCDQtfUBXYKDtnilkV8iKQNNSPpylawyEFbJLzUxI6qwINC3lw1m6\nxkBYpn1eYEWgaSkfztIb/jX7vMCKQNPSh4QINAItgJe6mZA+JESgEWgBvNTNhJQPhynHJ5I6\nKwJNS/lwlq4xqNnnBVajgR7fMijp/VFD1xgIK2SXmpmQ1FmtBtq5wRksZlsxc4xdamZCUmdF\noGmpbKOV2aVmJiR1VpuBbt1bBJrZVswcY5eamZDUWY0GepxCP8Y/9j9JEdSuRiuzL8Eh0EuF\nq8CWRAQ6wmoz0EMh0JltxcwxdqmZCUmdFYGmpbKNVmaXmpmQ1FltBhpTjiURgY6w2g20f1AI\noxFoFqvNQOOTFEsiAh1hNRpoHrzUzYQkJEWgmZI6KwJNS0JSBJopqbMi0LQkJEWgmZIOsOuz\nzhZ5hUAj0NrMISv20LQkJC070EPttNPLrV19RqDLCHTILjUzIamzItC0JCRFoJmSOisCTUtC\nUgSaKamzItC0JCR9lWu0zhY3qZJ8DlkRaFoSkmIPzZTUWRFoWhKSItBMSZ0VgaYlISkCzZTU\nWRFoWhKSItBMSZ21qEAP5bBrbG6t2tVoZfYlOARaCV7qZkISkiLQTEmdFYGmJSEpAs2U1FkR\naFoSkiLQTEmdFYGmJSEpAs2U1FkRaFoSkiLQTEmdFYGmJSEpAs2U1FkRaFoSkiLQTEmdFYGm\nJSEpAs2U1FkRaFoSkiLQTEmdFYGmJSEpAs2U1FkRaFoSkiLQTEmdFYGmJSEpAs2U1FkRaFoS\nkiLQTEmdFYGmJSEpAs2U1FkRaFoSkiLQTEmd1XigS/r20ZJ/pxA+Z7SdOs8OdEnfD13yTyPD\n55y2EwsCjUCLmS35jECXGehwELlmJqSyfRYEevqdQqtVEmtYJbFbYlXZQ6efYLb2HKwn/Efi\n+nto+BxrO7Eg0Ai0mNmSzwg0Ai1mtuQzAo1Ai5kt+YxAI9BiZks+q5wptGo0zVpGoOFzTtup\nc5VrOcwaTbIWEmiSHT7TbafOVb7bLqzEO5HqkrySG19J1Cn4PBcRaASaJckLgWZJ8kKgOZK8\nEGiWJC8EmiPJq+BAo1B7FQKNqqoQaFRVhUCjqioEGlVVIdCoqko10O4p/dY/v+/eJZSWWqsl\nN7oFbYo3Rbw683yT8NlfWzPQ3kVXLaERzQLZXdy2YWtqzY8rRbvIG1tzZWZik/DZX9tGoFuy\nmWWjKeL1mYlNwmd/bfU5dOvdUDgJo4ml64aDpl3kjT9CWwTa7Rg+bxXoxNRuBthSzTY1Ojm1\nI3qNEO8QaPjsL9AOdIQubVdLNdvC6KiXS71GiLcLNHyOrL1WoOd3OEb797YzmqBI9xoh3j7Q\nBM2/7bNyoKMARNcLzTYwOkmb6jVu+0aBhs/hGusEmn7ti3S9uNbaRkdpF3uNr7lNoOHzNoEO\nOozcXTCaGsQqRsdpF3jjxBsFGj5vE+j3mZ32dSfQHrTkIs2PvpNrrkW71GuMeG3mZfJ/3mdc\ny4GqqhBoVFWFQKOqKgQaVVUh0KiqCoFGVVUINKqqQqBRVRUCjaqqdAPdNMP2Ds29+3vr7t26\n23tzcLT+tq/z1VtlXNyc/pw7zYrPt5Cn6/fcnJ7aqTl33N+ntjl+u3DTKq/bn3FbY5v2clsP\nmeS+Bnyeke4gvHXfC/Yx++pCkPiHOZw/slhPmti/XW+/jz4Y/d+f5vmA//bpeGsT4vVBLm7+\nNvF43nF3r30m9KdpH49r+4roPeRxVm2f8fWs/12Nmea+0g/7YKQ7CG/d19Y2CnQEepQp/K94\noIeRxUp1EN0ebgjvT4/zuDRfzaW7/RpSMmrjOC7N8UEsvl+e+3N3vKtU2PFX3+/f8Mjf296x\nQ3Pu/r8dhzF4PM6qz0G8rO//u51f4dmKe/DR9coz0h9EuO70z8ZmB9Cz3u/PyzKaxMhipTqQ\nprkPnV6Hx7mbeAy3x+bqaIGHs8VbeUzzDJOOp/mjfXMeZ9Wv5nvURv08PJu35SYedk+4WzQ7\nEegxMomRRbtSwB2rn1s8ZxtDj93z6NCMdwItunirPfSs4+erSTfpuF6b4QquUzB3ePN4qx6G\nwwTX+utrr70Rd3o/5g1ivu5GgV6CDnsndhNOs+320D3zc8J86p5h12EU/e3J055Y9/Nwx10c\nTJDW9Xje8fCS2E06Tqcnwa1tDpef6RDvzeMN5TbE17N+VXDaR3cW7BnpDSJc97FVoGPQox5M\n4v9ex+bevDkcWaw0B9K898f9U+y7mzr/DLdfnvamupGLx3c/VvZ43vHrDY7zGO3H/evQLT78\nuWuEqz664X1vGWjaR+phfxrpDsIH91i3NvsJPeluoO/jhc+xQL8jQvalh/376u+3f46dnb30\nr6c9/2kHKm/xcH96uV7V47Dj/kB2dvDXTR8u56P71hy16rF7cDYLdMTH2Quza+Q4iPmYNwr0\nIrTf+3MC/YhMOX4XZnSKAzmPT6D+IKTtZqP95vvbu6e5iLPFlwl35VfuGU/j7BfcCpeHq966\nGZ1r/fiCuRV3yDwzcljY0utuEuhFaK/31wT6EZtDX9KJVhzIkNwhy/07HM9jo243Pdx3NBdx\nvvjwfo9gVY8JnvntnVw+W7WbU7nWn94PyDbcLpvz/+E105sG4ax7fB0rvnd3W5vt9+kudfYH\nkYPCQ/JtJL2B/L3mnufmec5t6ParGeb/ruYgEouvjfuCs1bNO+4OnU9+v92e4I9YTjAfm8n6\n/n3oLbl9Zuf/p5HOINx1v5u2T/RvOz75tjU77NNZenc+ORgJ9BQRqvQGcnkde/72k9Gf55Rp\nmD59+5qDSC3+2uJtO7/jV4VPpMNrwnfzlhPMt9Y7fEmdmFXlnpa/+3Yi8DRyGoT3+BxfzY/v\nDewH7eF/BSOJjyxSegNxvsl3eBa9ruMYguJqzpjIxeMrypoe+x1Pxyl+v9/H/tqMu7+cYv6Z\nrD9c1jxPGPGRfNhfRr4H4T0+j59T1/j0M21gP2gP/8AIdHLSsebcCYXavBBoVFWFQKOqKgQa\nVVUh0KiqCoFGVVUINKqqQqBRVRUCjaqqEGhUVYVAo6oqBBpVVf0fiRW5O1fQci8AAAAASUVO\nRK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec.AWAPART=df.dm.holder[df.dm.holder[,\"AWAPART\"]>0,\"AWAPART\"]\n",
    "vec.ABYSTAND=df.dm.holder[df.dm.holder[,\"ABYSTAND\"]>0,\"ABYSTAND\"]\n",
    "vec.APERSAUT=df.dm.holder[df.dm.holder[,\"APERSAUT\"]>0,\"APERSAUT\"]\n",
    "vec.APLEZIER=df.dm.holder[df.dm.holder[,\"APLEZIER\"]>0,\"APLEZIER\"]\n",
    "plots.hist.plc=list()\n",
    "plots.hist.plc[[1]]=ggplot()+geom_histogram(aes(x=vec.AWAPART),breaks=seq(1,10))+labs(x =\"AWAPART\")\n",
    "plots.hist.plc[[2]]=ggplot()+geom_histogram(aes(x=vec.ABYSTAND),breaks=seq(1,10))+labs(x =\"ABYSTAND\")\n",
    "plots.hist.plc[[3]]=ggplot()+geom_histogram(aes(x=vec.APERSAUT),breaks=seq(1,10))+labs(x =\"APERSAUT\")\n",
    "plots.hist.plc[[4]]=ggplot()+geom_histogram(aes(x=vec.APLEZIER),breaks=seq(1,10))+labs(x =\"APLEZIER\")\n",
    "# Draw the plots\n",
    "options(repr.plot.width=6,repr.plot.height=2)\n",
    "library(gridExtra)\n",
    "do.call(\"grid.arrange\", c(plots.hist.plc, ncol=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although APLEZIER (the number of boat policies) has the largest magnitude of coefficient, its frequency is very low compared to AWAPART (the number of private third party insurance) and APERSAUT (the number of car policies). The same perspective can be applied to other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAADwCAMAAAAeuqOxAAAAOVBMVEUAAAAzMzNNTU1ZWVlo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\nkCjB0JAo/R8NZ1VZT2i7tQAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec.MOSTYPE8=df.dm.holder[df.dm.holder[,\"MOSTYPE8\"]>0,\"MOSTYPE8\"]\n",
    "vec.MOSTYPE12=df.dm.holder[df.dm.holder[,\"MOSTYPE12\"]>0,\"MOSTYPE12\"]\n",
    "vec.MRELGE=df.dm.holder[df.dm.holder[,\"MRELGE\"]>0,\"MRELGE\"]\n",
    "plots.hist.plc2=list()\n",
    "plots.hist.plc2[[1]]=ggplot()+geom_histogram(aes(x=vec.MOSTYPE8),breaks=seq(1,10))+labs(x =\"MOSTYPE8\")\n",
    "plots.hist.plc2[[2]]=ggplot()+geom_histogram(aes(x=vec.MOSTYPE12),breaks=seq(1,10))+labs(x =\"MOSTYPE12\")\n",
    "plots.hist.plc2[[3]]=ggplot()+geom_histogram(aes(x=vec.MRELGE),breaks=seq(1,10))+labs(x =\"MRELGE\")\n",
    "# Draw the plots\n",
    "options(repr.plot.width=6,repr.plot.height=2)\n",
    "library(gridExtra)\n",
    "do.call(\"grid.arrange\", c(plots.hist.plc2, ncol=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOSTYPE8 (Middle class families) has the 3rd largest magnitude on the coefficient as well as having the relatively large number of frequency. In such a view, customers who are categorised as the middle class families could be the first option to approach for marketing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "James, G., Witten, Daniela, author, Hastie, Trevor, author, & Tibshirani, Robert, author. (2015). An introduction to statistical learning : With applications in R (Springer texts in statistics).\n",
    "\n",
    "Minitab, LLC. (2019). What are complete separation and quasi-complete separation?  Retrieved from:  https://support.minitab.com/en-us/minitab/18/help-and-how-to/modeling-statistics/regression/supporting-topics/logistic-regression/what-are-complete-separation-and-quasi-complete-separation/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
